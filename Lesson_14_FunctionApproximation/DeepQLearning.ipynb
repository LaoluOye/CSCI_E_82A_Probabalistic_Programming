{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Q Learning\n",
    "\n",
    "## CSCI E-82A\n",
    "\n",
    "## Stephen Elston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To date we have only considered reinforcement learning problems with a small number of **discrete states**. So far, we have applied **tabular algorithms** to the solution of RL problems. However, tabular methods will not work in cases where the tables are too large to be held in computer memory or where states are not discrete values. \n",
    "\n",
    "But, many practical problems have eight very large numbers of discrete states or have continuous states. Some example of such problems:  \n",
    "1. A Game such as chess or backgammon with a great number of possible board states. While the number of states is **countably finite** there are far too many for tabular solutions. For example, consider that each piece in a chess game can occupy any of 64 positions, and that there are anywhere between 32 pieces and 2 pieces on the board at a given time step. This situation leads to an explosion in possible states. Other games, such a Go, have far more states than chess.   \n",
    "2. A simple flight control system for a drone which has an infinite number of states in terms of 3-dimensional velocity, acceleration, and position, along with pitch yaw and role. All 12 of these variables have **continuous values** and, thus, an **infinite number of states**.   \n",
    "\n",
    "To address such problems we must have a better representations. In this lesson we will focus on a powerful class of representations known as **function approximation**. By using function approximation we can represent a large number of states, even an infinite number, with a limited number of **parameters**. Using function approximation problems of great complexity can be tackled, at least in theory.  \n",
    "\n",
    "A reinforcement learning agent using function approximation is illustrated schematically in the figure below. \n",
    "\n",
    "<img src=\"img/AgentEnvironment.JPG\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center> **Reinforcement Learning Agent with Function Approximation Representation and Environment** </center>  \n",
    "\n",
    "In this lesson we will only address function approximation methods for **episodic** tasks. \n",
    "\n",
    ">**Suggested reading:** The following sections of Sutton and Barto, second edition, provide additional scope for the topics of this lesson: 9.1, 9.2, 9.3, 9.4, 9.5, 10.1, and 10.2.\n",
    "\n",
    ">**For further exploration:** The resources of [Open AI Gym](https://gym.openai.com/) provide a rich set of simulators along with a framework to help you construct and test RL algorithms. \n",
    "\n",
    ">**Code examples in depth:** *Deep Reinforcement Learning Hands-On* by Maxim Lapan, Packt, 2018, provides considerable detail on deep Q learning. The book contains in-depth examples and discusses important implementation details. The examples in this book use the PyTorch deep learning framework. \n",
    "\n",
    "In order to run all of the examples in this notebook you will need to install [Keras](https://keras.io/) and h5py; `pip install h5py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation for Non-Tabular RL\n",
    "\n",
    "The main question we will address in this lesson is what representations can we use when tabular methods will not work. The idea key idea is to **encode** a large, possibly infinite, number of states with a **few parameters**. Thus, **state values** or **action values** are represented by some **function of the state** of the environment.  \n",
    "\n",
    "There are, in fact, many possible approaches to this problem. Here we will focus on function approximation methods of which a few examples are: \n",
    "1. Simple **linear** and **polynomial** representations,\n",
    "2. **Fourier basis function** representations,\n",
    "3. **Course coding** using overlapping circular or elliptical regions,\n",
    "4. Various forms of **tile coding**,\n",
    "5. **Radial basis functions** or kernels,\n",
    "5. **Fully connected** deep neural networks, \n",
    "6. **Convolutional** deep neural networks. \n",
    "\n",
    "Each of the first five methods involve **coding** using some type of **basis function**. Basis functions rely on an implicit assumption that **nearby states have similar values**.  The representation is then **linear in the parameters** and **linear solution methods** are used to find these parameters. Linear methods have the advantage of computational efficiency. Further, at least for **on-policy** algorithms, **convergence is guaranteed**.     \n",
    "\n",
    "The deep neural networks provide a distinctly nonlinear function approximation method. Typically, deep neural networks are used for **off-policy Q-Learning** methods. The convergence properties of these algorithms can be problematic. In fact, there are few guarantees of convergence with **off-policy function approximation** algorithms.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile coding\n",
    "\n",
    "Tile coding is a flexible and expressive function approximation method. The basic idea is simple. The **state space is divided** into small patches using a regular pattern of **geometric shapes** or **tiles**. The function approximation has one parameter (weight) for each tile.    \n",
    "\n",
    "An example tile coding of a two dimensional state space is shown in the figure below. In this case, a uniform 8x8 set of tiles are used, leading to a representation with 64 parameters. \n",
    "\n",
    "<img src=\"img/Tile1.JPG\" alt=\"Drawing\" style=\"width:300px; height:300px\"/>\n",
    "<center> **Two-dimensional state space encoded by 8x8 rectangular tiles** </center>\n",
    "\n",
    "In the above diagram the states shown by **X** are in the same tile and will be coded with the same parameter. The states show by **O** are in different tiles and are coded with different parameters. \n",
    "\n",
    "However, the tile codings are far from unique. Consider the tiling of the same state space shown in the figure below. In this case the tiles are a 4X16 grid. As in the first case, there are still 64 parameters. \n",
    "\n",
    "<img src=\"img/Tile2.JPG\" alt=\"Drawing\" style=\"width:300px; height:300px\"/>\n",
    "<center> **Two-dimensional state space encoded by 4x16 rectangular tiles** </center>\n",
    "\n",
    "In the above coding the states shown with **O** are in the same tile and represented by the same parameter. But, the states shown as **X** are now in different tiles and are represented by different parameters. \n",
    "\n",
    "A great many tile coding schemes are possible. Commonly, multiple tiling schemes are used simultaneously. This practice allows for the capture of information at **different scales**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep neural networks\n",
    "\n",
    "Deep neural networks are powerful function approximation methods. In most cases one of two deep neural network architectures are used:\n",
    "1. Fully connected network are used for cases where there are complex and highly nonlinear relationships between state values or action values. \n",
    "2. Convolutional networks are useful for cases where there is value coherency between adjacent states. Common examples include images and time series data.  \n",
    "\n",
    "In principle deep neural networks can approximate even highly complex nonlinear functions. Neural networks have been reviewed in a previous lesson. Here, we will just summarize some of the drawbacks of this attractive representation. \n",
    "1. Given the large number of parameters a large number of episodes are required for training. It is not unusual for several tens of millions of episodes to be required. Therefore, training time can be significantly longer than for other algorithms.\n",
    "2. As a result of the large number of parameters (high degrees of freedom) over-fitting is a constant problem. Careful attention must be paid to regularization methods. \n",
    "3. Deep neural network are known to have **brittle behavior**, wherein small changes in the input can result in surprising or unexpected predictions.\n",
    "\n",
    "The foregoing not withstanding, trained neural network models can be reasonably computationally efficient. In fact, prediction using trained neural network models is preformed routinely, even in embedded environments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Function and Stochastic Gradient Decent\n",
    "\n",
    "Following the discussion above, basis function methods are linear in their parameters. In the following we will express these parameters as a vector of model weights, $\\mathbf{w}$. We can then represent the approximate state value function with state $x(s)$ as:\n",
    "\n",
    "$$\\hat{v}(s,\\mathbf{w}) = \\mathbf{w}^T \\mathbf{x}(s) =  \\sum_{i=1}^d   w_i  x_i(s)$$\n",
    "\n",
    "In principle, **stochastic gradient decent** algorithms are an efficient way to solve for the weights, $\\mathbf{w}$. At each step the update is just:\n",
    "\n",
    "$$\\mathbf{w}_{t+1} = \\mathbf{w}_t + \\alpha\\ E_{\\hat{p}data}\\Big[ \\nabla_{w} J(\\mathbf{w}_t) \\Big]\\\\\n",
    "= \\mathbf{w}_t + \\alpha  \\big[v_{\\pi}(s) - \\hat{v}(S_t, \\mathbf{w}_t) \\big]\\nabla_w \\hat{v}(S_t,\\mathbf{w}_t)$$\n",
    "\n",
    "where, $\\hat{p}data$ is the mini-batch, and gradient is given by:   \n",
    "\n",
    "$$\\hat\\nabla_w {v}(S_t,\\mathbf{w}_t) = \n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\hat{v}(S_t,\\mathbf{w}_t)}{\\partial w_1} \\\\\n",
    "\\frac{\\partial \\hat{v}(S_t,\\mathbf{w}_t)}{\\partial w_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial \\hat{v}(S_t,\\mathbf{w}_t)}{\\partial w_d}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "In many practical algorithms, $\\hat{v}(s)$ is a **bootstrapped** approximation. This means are error term and gradient are not exact. We call such algorithms **semi-gradient decent** methods as they use an approximation of the gradient. This approach generally works well, but does not have the strong convergence guarantees of stochastic gradient decent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Approximation Error\n",
    "\n",
    "As already noted, when tabular algorithms are not feasible, we must resort to function approximation. We can use function approximation for both state values, $\\hat{v}(s)$, and action values, $\\hat{q}(s,a)$. We should always keep in mind that we are dealing with **approximations** and will never know the true state values, $v_{\\pi}(s)$, and action values, $q_{\\pi}(s,a)$. There will always be some **error** between the true values and the approximated values. For example, for state value approximation we can express this error as the **mean squared value error**:\n",
    "\n",
    "$$\\overline{VE}(w) = \\sum_{s \\in S} \\mu(s) \\Big[ v_{\\pi}(s) -  \\hat{v}(s,\\mathbf{w}) \\Big]^2$$  \n",
    "\n",
    "Here, $\\mu(s)$ is a weight indicating home important the state $s$ is. For on-policy RL, $\\mu(s)$ is a probability known as the **on-policy distribution**. \n",
    "\n",
    "A similar error metric can be constructed for $\\hat{q}(s,a)$.  \n",
    "\n",
    "In practical terms there is a trade-off between the complexity of the approximate representation and the error. More complex representations require more parameters, but have lower error and vice versa. This situation is exactly analogous to the bias-variance trade-off, familiar from machine learning.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mountain Car Problem\n",
    "\n",
    "The [mountain car problem](https://en.wikipedia.org/wiki/Mountain_car_problem) was first proposed in the [Andew Moore's Ph.D. dissertation (1990)](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.2654). The mountain car problem has become a canonical testbed for many reinforcement learning algorithms. \n",
    "\n",
    "In this problem an under-powered car must climb a steep hill. However, the car does not have sufficient engine power to climb the grade. The car must travel up another hill in order to gain sufficient speed (actually kinetic energy) to climb the large hill. \n",
    "\n",
    "The position, $x$, and velocity, $\\dot{x}$, of the car are the state variables. The updates of the state variables at each time step are determined by the following equations: \n",
    "\n",
    "$$x' = x + \\dot{x} \\\\\n",
    "\\dot{x}' = \\dot{x} + 0.001 * \\ddot{x} - 0.0025 * cos(3 * x)$$\n",
    "\n",
    "The object of this problem is to find the optimal acceleration given the car state to allow the car to get to the top of the hill. The car has three acceleration states, $\\ddot{x}$, which must be selected by the agent:\n",
    "\n",
    "$$\\ddot{x} = \\{ -1.0, 0.0, 1.0 \\}$$\n",
    "\n",
    "The position and velocity are bounded, with the goal at the upper bound of position:\n",
    "\n",
    "$$-1.2 \\le x \\le 0.5 \\\\\n",
    "-0.07 \\le \\dot{x} \\le 0.07$$\n",
    "\n",
    "The reward at each time step is -1.0 and the reward for reaching the goal is 100.  \n",
    "\n",
    "The car is randomly initialized using a uniform distribution:\n",
    "\n",
    "$$p(x_0) = uniform(-0.6 \\le x_0 \\le -0.4)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mountain car problem is hard\n",
    "\n",
    "At first glance, the mountain car problem may seem like it should have an easy solution. However, looks are deceptive. The learning an optimal policy for this problem is difficult. In fact, conventional control theory approaches fail to provide solutions. Some reasons for this difficulty include:\n",
    "1. The non-linear coupling between the two state variables, which makes the state transitions between the infinite number of states hard to predict.\n",
    "2. The delayed reward which is only observed when the goal is achieved. This fact is common to many difficult RL problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of car environment\n",
    "\n",
    "The code in the cell below **simulates the car environment**. Two functions are used by the agent to interact with the environment:\n",
    "1. The `sim_car` function returns a state transition and a reward, given the agent's current state and an action. In addition, a flag is returned to indicate if the goal has been reached.\n",
    "2. The `initialize_car` function returns a random starting position for the car within the specified bounds. \n",
    "\n",
    "Taken together, calls to these two functions define the **boundary between the agent and the environement**. Execute the code in the cell below to exercise these functions and examine the resulting plots for a case where the acceleration is set to 0. \n",
    "\n",
    ">**Note:** An Open AI Gym [environment simulator](https://gym.openai.com/envs/MountainCarContinuous-v0/) for the mountain car problem is available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEKCAYAAAArYJMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4VFX6wPHvm0YKKQQSCBAIJXQIkFAFRcWuYANBqnTFXnb1t9a1rWuvgNKLICoK9oK6itSE0HsJLQESQgrp5f39McMuy1ICmcmdmZzP88yTmZs797zDDHnnnnPue0RVMQzDMAxn8bI6AMMwDMOzmURjGIZhOJVJNIZhGIZTmURjGIZhOJVJNIZhGIZTmURjGIZhOJVJNIZhGIZTmURjGIZhOJVJNIZhGIZT+VgdgCuoU6eOxsTEWB2GYRiGW0lKSspQ1Yjz7WcSDRATE0NiYqLVYRiGYbgVEdlXkf1M15lhGIbhVCbRGIZhGE5lus4q4bUftvPNxjTqhfgTFepPdHggHaPD6BgdRq0gP6vDMwy3lFNYwqaD2aw/mM3Oo7kczSniaG4h2QUleIngJUINXy/qhwbQICyARrVt/+/iosOoWcP8SXNF5l2phKYRQbStH8Lh7EJW7c3ky3WHKLevutAsIoir29bjunb1aN8gFBGxNljDcFGqyu70E/yw+Qg/bjnC+gNZ//5dVKg/dUP8iakdRK1APxSltFwpLCkjNauQX7YfJT23CAAvgbb1Q7mmbV2ubx9F04iaVr0k4zRi1qOBhIQEdcRkgLyiUjYczGbdgSyW7Upn5Z5MysqVRuGBDO3eiDsSGhEa6OuAiA3D/RUUl7F43SHmrNzH5tQcAOKiw7iiZSSdGoXRvkFohXoGsgtKSN5/nLX7jvPn7mMk7TsOQJuoEIb1aMwtnRrg7+vt1NdSXYlIkqomnHc/k2gcl2hOl5lXzM9bjvDZ2oOs3ptJgK83t3ZuwMTLm1M/LMDh7RmGO8jOL+HDP3YzZ8U+cgpLaVk3mMFdo7m2XRT1Qv0rffy07AK+3XiYz5MOsiUth1qBvgzp1pjRvZqYLm0HM4nmAjgr0ZxqS2oOs5an8EXyIRAY3r0x91zenHDzwTeqibyiUmb8uZcpv+8ht7CU69rVY2TPGLo2CXdK17KqsmpvJtOX7eWnrUeo6efDhD7NGHVJEwL8zBmOI5hEcwGqItGcdCirgLd+2sHnaw8S5OfDY9e2ZEi3xnh7mTEcwzOpKt9vOsxzX23hcE4hfVvX5ZGrW9A6KqTKYth+OJdXf9jGz1uPUjekBk/d2IYb2keZsdNKMonmAlRlojlp19FcnvtqC3/szKBjdBgv39q+Sv/jGUZVOJCZz9OLN/Hr9nTaRIXw/M3tiG9cy7J4Vu05xvPfbGHToRz6to7k7/3bmW7sSjCJ5gJYkWjA9k1v8bpUnv96C9kFJTx0VQsmXNbMnN0Ybk9V+SL5EE8v3oyq8vDVLRnRozE+3tZfuldaVs6MP1N4/afteIvwbL+23B7f0JzdXASTaC6AVYnmpON5xTy5eBPfbEijR9PavHFHHFGh5luW4Z6yC0p48stNfLU+la5NwnljYBwNawVaHdb/OJCZz2OfrWflnkz6d6zPCze3I9jfzAq9ECbRXACrEw3YvgF+lnSQZ5Zsxs/Hi7cHdeKyFuetVWcYLmVrWg7j5iSSllXoFmfoZeXKB7/u4q2lO2lYK4D37+xMuwahVoflNiqaaKw/jzUAEBEGJETzzf29qRfiz10zVvPh77sxXwQMd7FkfSq3frCcklJl4YQeTLy8uUsnGQBvL+G+K2P5ZFx3ikvLuX3ycr7ekGp1WB7HJBoX06ROEIvu6cl17aJ46dttPPjJOgpLyqwOyzDOqrxc+cd327h/fjLtGoSw5L5L6NzIugH/i5EQE86Se3vRrn4o936czGs/bKe83HzJcxSTaFxQoJ8P793ZiceuacmS9akMnbqKrPxiq8MyjP9RVFrG/QuSmfyv3Qzp1oh5Y7oTGVz5iy6tEBFcg4/HdmdQl2je+3UX981PNl/yHMThiUZEvERkk6OPW92ICBMvb867gzux4WA2t09ewaGsAqvDMox/y84vYdi01Xy9IY0nrmvFCze3w8/Hvb+7+vl48fKt7XnyhtZ8szGNkTNWk1NYYnVYbs/hnwpVLQfWi0gjRx+7OrqxQ31mj+7KkZxCbv3gT7YfzrU6JMPgaE4hA6YsZ93+LN4e1JHxlzXzmOnBIsKY3k15e1BHkvYdZ+DkFRzJKbQ6LLfmrK8fUcBmEVkqIktO3pzUlsfr3rQ2n03oCcCgD1ew6VC2xREZ1dmhrAIGTlnBweMFzLyrC/07NrA6JKfo37EB00d24UBmPndMWUGq6VG4aE6Z3iwil51pu6r+y+GNOYArTG+uiH3H8rjzo1XkFpYwa1RXOrnZgKvh/lIy8hgydRU5hSXMvKurpVf5V5W1+48zYvpqQgN8mT+2O9HhrndNkFXMdTQXwF0SDdi+Td750UqOnShm1qguxDcOtzoko5pIycjjjg9XUFxazpzR3arV9SYbD2YzdNoqgvy8+Xhsd2LqBFkdkkuw9DoaEekuImtE5ISIFItImYjkOKOt6qZBWAALx/cgMrgGI6ev+a9FogzDWQ5k5nPnRyspLi1n/rju1SrJALRvGMr8sd0pLC3nzo9WciAz3+qQ3IqzxmjeAwYDO4EAYIx9m+EAdUP8mTe2G2FBvgyfvprNqWbMxnCe1KwCBn+0krziMuaO6UaretWz+Gub+iHMGd2VE0WlDJm6isPZZoJARTltLqKq7gK8VbVMVWcAfZzVVnUUFRrAx2O6E+TnzbBpq9l5xMxGMxwvPbeIIVNXkZ1fwpzRXWlbv3qdyZyubf1QZo/uRmZeMXdOXfnvZaSNc3NWoskXET9gnYj8U0QeAkynpoNFhwfy8djueHsJw6atNtfZGA6VU1jCyBmrScsuYOaoLnRoGGZ1SC6hY3QY00d2IS2rkBHTV5NrrrM5L2clmmH2Y98L5AHRwG1Oaqtai6kTxOxRXckrLmXYtFVk5pkKAkblFZaUMXZWItsP5zJ5aLyZdHKark3CmTS0MzuO5DJudpKpIHAezko0GUCxquao6nPAY4CpVOckraNCmDaiC4eOF3DXjNXkFZVaHZLhxsrKlfvnJ7M6JZPXB8bRp2Wk1SG5pD4tI3ltQBwr9hzj4YXrKDO10c7KWYlmKXDqZPMA4GcntWVg+4b1/p2d2ZSaw70fr6W0rNzqkAw3pKo899VmftxyhGdubOOxF2M6ys2dGvDkDa35duNhnvtqs6m2fhbOSjT+qnri5AP7fXOVk5P1bVOX5/u349ft6Ty9xHzojQv30R97mL1iH+MubcrIS5pYHY5bGNO7KeMubcrsFfuY+sdeq8NxST5OOm6eiHRW1bUAIhIPmJHqKnBnt0YcPJ7PB7/tJrpWIHf3aWZ1SIab+HpDKi99u40bOkTx+LWtrA7HrTx+bSsOHS/gxW+30qBWANe3j7I6JJfirETzIPCpiJwcl4kC7nBSW8ZpHr26JQePF/DK99toUCuAfnH1rQ7JcHFJ+47z8ML1dImpxesD4vBy8QXLXI2Xl/D6wDgO5xTy0CfrqBviXy3K81SUU7rOVHUN0Aq4G7gHaK2qSc5oy/hfXl7CqwM60DUmnEc/XU/y/uNWh2S4sAOZ+YybnUhUqD8fDkvA39fb6pDckr+vNx8NTyAq1J9xsxNN9YBTOPOCzRJV3aSqG1XVTDSvYjV8vJk8LJ56If6MnZ1krrExzii3sITRs9ZQUlbOtBFdqBXkZ3VIbi08yI9pI7tQUlbOmFmJnDAzQAGzwqZHCw/yY9qIBIpKyhgzK9FMezb+S1m5ct/8ZHan5zFpaDzNI2taHZJHaBZRkw+GxLMr/QQPzE82055xcKIRkUvsP2s48rj2Y4aLyE8istP+84wdoPYCnuvst2q/Bk5s3WDeG9KZ7YdzePCTdWYddOPf/vHdVn7bns5z/dpySfM6VofjUXrF1uHZfm1Zuu0or3y/zepwLOfoM5p37D9XOPi4AI8DS1U1Ftt1Oo+fZb8CVe1ov/VzQhxu57IWETx1Yxt+2nKEt37eYXU4hgv4POkgH/2xl+E9GjO0e2Orw/FIw7o3ZniPxnz4+x4WrT1odTiWcvSssxIRmQE0EJF3Tv+lqt5fiWP35z+FOWcBvwF/rcTxqpWRPWPYkprDO7/solVUiJl+WY0l7z/OE19spEfT2jx1Yxurw/FoT93Yhp1HTvD4oo00jahJx+jqWS/O0Wc0NwI/AIVA0hlulVFXVdMA7D/PVhfDX0QSRWSliNx8toOJyDj7fonp6emVDM31iQgv3NKOzo3CeGTherakmuWBqqMjOYWMn5NE3ZAafDCkM77eZpjWmXy9vXh/SGcig2swfk4iR3Oq59ICzlrKOU5V11/E834G6p3hV38DZqlq2Cn7HlfV/xmnEZH6qpoqIk2BX4ArVXX3udp1pxU2K+tobiH93v0TH2/hq3t7mVlG1UhRaRmDPlzJ9sO5LLqnZ7VdV8YKW9NyuPWD5bSKCmbBuO7U8PGMKeSWrrAJHBORL0TkqIgcEZHPRaTh+Z6kqn1Vtd0ZbouBIyISBWD/efQsx0i1/9yDrXutk8NelQeIDPZn8rB4juYUcd/8ZFMTrRp5dslmkvdn8dqAOJNkqljrqBBeHxhH8v4snl2yxepwqpyzEs0MYAlQH2gAfGXfVhlLgBH2+yOAxafvICK1Ts54E5E6wCVA9XtXz6NjdBgv3NyOZbsyePWH7VaHY1SBeav2MX/1Ae7p08yMz1nk+vZR3N2nGfNX7+fjVfutDqdKOSvRRKrqDFUttd9mAhGVPOY/gKtEZCdwlf0xIpIgIlPt+7QGEkVkPfAr8A9VNYnmDAZ2iWZY98ZM+X0PS9abFRw8WdK+TJ5dspk+LSN45OqWVodTrT16dUsubRHBM0s2kbSv+lTscNYYzc/ATGC+fdNg4C5VvdLhjTlAdRqjOVVxaTl3frSSzak5fDHR9Nl7oqO5hdz4zjIC/LxZMrEXoYG+VodU7WXlF9PvvT8pLCnj6/t7ERnsb3VIF83qMZpRwEDgMJAG3G7fZrgQPx8vPhjSmWB/H8bPSSK7wFQK8iQlZeVMnLeW3MJSJg+NN0nGRYQF+jFlWDw5hSXcOy+ZkmowTuqsopr7VbWfqkaoaqSq3qyq+5zRllE5kSH+TBramdSsAh4ylQM8yovfbGVNynH+cVt7WkeZs1VX0joqhFdu68DqlExe+nar1eE4nZlEbxDfOJynb2zDL9uO8vbSnVaHYzjAF8kHmbk8hdG9mphVMl1U/44NGHVJE2b8mcKXyYesDsepTKIxABjavTG3dW7I20t38su2I1aHY1TCltQcnli0kW5Nwnn8OrOAmSt74vpWdG0SzuOLNrA1zXMvojaJxgBslQNevKUdbeuH8OCCdew7lmd1SMZFyM4vYcLcJMIC/HjvTnPlv6vz9fbivTs7ERrgy4S5njtO6pRPoYjUEJE7ReT/ROTpkzdntGU4jr+vN5OHxiMijJ+TREFxmdUhGRegvFx58JNk0rIL+GBoZyKCHV5E3XCCyGB/PhhiGyd92EPHSZ31dWcxtiKYpUDeKTfDxUWHB/L2oI5sP5LLE4s24Izp74ZzvL10J79uT+fpm9rSuZFZRtidxDcO56kb27B021He/WWX1eE4nKOrN5/UUFWvddKxDSfr0zKSh/u24PWfdtAxOoyRlzSxOiTjPH7ZdoS3l+7kts4NGdqtkdXhGBdhWPfGrNufxVtLd9AhOpTLW56tbrD7cdYZzXIRae+kYxtVYOLlzenbOpIXvtnKmpRMq8MxziElI48HF6yjbf0QXrylHSJidUjGRbCNk7anVb0QHpif7FHjpM5KNL2AJBHZLiIbRGSjiGxwUluGE3h5CW/c0ZHo8EDumbe22pY3d3X5xaVMmJuEiDB5aDz+vp5RFbi6CvDzZop9nHTC3LUeM07qrERzHRALXA3chG2dmpuc1JbhJCH+vkweGs+JwlLunreW4lLPv4LZnagqj3++ke1Hcnl7kO1LgeH+GtW2jZNuO5zD/32x0SPGSZ1VGWAfEIYtudwEhJnKAO6pZb1gXh3QgaR9x3n+a1Of1JVMW7aXJetTeeSqFvTxoP584z/jpF8kH2Lm8hSrw6k0Z01vfgCYh20VzEhgrojc54y2DOe7sUN9xl3alDkr9/Fp4gGrwzGA5bszePm7bVzdpi739GludTiGE0y8vDlXtanLC99sZeWeY1aHUynO6jobDXRT1adV9WmgOzDWSW0ZVeAv17Tkkua1+duXm9hwMMvqcKq11KwC7vs4mZjagbw+MA4vLzP474m8vIQ3BsbRuHYgE+etJTWrwOqQLpqzEo0Ap45ildm3GW7Kx9uLdwd3JqJmDSbMSSLjRJHVIVVLhSVljJ+TRFFpOVOGJRDsbyoye7Jgf18+HJZAUWk5d89NorDEPScHOHOFzVUi8qyIPAusBKY7qS2jioQH2cqbZ+YXc8+8tdWivLkrUVWeWLSRjYeyefOOjjSPrGl1SEYVaB5ZkzcGxrH+YLbbTg5w1mSAN4C7gEzgOLZFz950RltG1WrXINRW3nxvJn//ykwOqErTlu3li+RDPHxVC65qU9fqcIwqdHXbejzYN5ZFaw8x/c8Uq8O5YE6pDCAic1R1GLD2DNsMN9e/YwO2pOYw5fc9tKkfwuCu5kp0Z1u2M4OXvt3KNW3rcu/lZvC/Orr/ili2puXw4jdbaFk3mF6xdawOqcKc1XXW9tQHIuINxDupLcMCf7m2Fb1j6/D04k2s3msqBzjT3ow87pmXRPPImrw+sKMZ/K+mvLyE1wfaukwnfryWlAz3qRzg0EQjIk+ISC7QQURyRCTX/vgotkKbhofw9hLeG9yZ6FqBTJibxIHMfKtD8kjZBSWMnrUGby9h2ogu1KzhrPKEhjuoWcOHj4YnIAKjZ60hp9A9lhVwaKJR1ZdVNRh4VVVDVDXYfqutqk84si3DeqGBvkwdkUBpWTljZiVyoqjU6pA8Slm5cv/8ZPYfy2fS0Hhz5b8BQOPaQUwaEs++Y/nc93EypW4wKcfRZzQnl/P7VEQ6n35zZFuGa2gaUZP3h3RmV/oJHlyQTJkHrqVhlRe+2cK/dqTz/M3t6N60ttXhGC6kR7PaPH9zO/61I52Xvt1mdTjn5ejz8IeBccDrZ/idAlc4uD3DBfSOjeCZm9rw9OLNvPTtVp66sY3VIbm92StSmPFnCqMuaWImWxhnNLhrI3YcyWX6n3tpEhHEsO6NrQ7prByaaFR1nP3n5Y48ruH6hveIYW9GHtOW7SWmdiDDesRYHZLb+nX7UZ5dspm+rSP52w2trQ7HcGFP3tCG/cfyeWbxJhrWCnDZNWycVetsgIgE2+8/KSKLRKSTM9oyXMeTN7Shb+tInlmymV+3H7U6HLe0NS2H+z5OpnVUCG8P6oS3mWFmnIO3l/DO4E60qhfCvfPWsiU1x+qQzshZ05ufUtVcEekFXAPMAiY7qS3DRXh7CW8P6kTrKNuHftOhbKtDciuHsgoYOWM1NWv4MG1EF4LMDDOjAoJq+DB9ZBeC/X0ZNXMNadmuVxPNWYnmZEGeG4BJqroY8HNSW4YLOfmhDwv0Y+SM1ew/ZqY9V0R2fgkjp68mv6iMmaO6UC/U3+qQDDdSL9Sf6SO7cKKolJHT15Cd71rTnp2VaA6JyBRgIPCtiNRwYluGi6kb4s+sUV0pLVeGT1/FMVOA85wKS8oYOzuRfcfymTI8nlb1QqwOyXBDbeqH8OGwePZknGDs7ESXKsDprD/+A4EfgGtVNQsIBx5zUluGC2oeWZNpIxJIyy5k1Mw15hqbsygtK+f++cmsTsnk9YFx9GzmPmVFDNfTs3kd3hjYkdUpmTy4YJ3LXG7grKKa+cBu4BoRuReIVNUfndGW4briG4fz3p2d2ZSaw9hZrvUNyxWUlyt/+XwDP245wrM3teGmuPpWh2R4gJvi6vP0jW34fvNhHv98A+UukGzMCpuGU13Vpi6vDejAyr3HuPdjs7TASarK37/ewqK1tmrMIy9pYnVIhgcZ1asJD1wZy6dJB/n711ssX1rAWdNaTq6wmQcgIq8AK4B3ndSe4cJu6dSQvKIynvxyEw8vXM9bd3Ss1tN2VZXXf9zBzOUpjOnVhPuuMNWYDcd7sG8seUWlTF22l6Aa3jx2TavzP8lJnJVozAqbxn8Z2r0xJ4pK+cd32/AWeH1g9Uw2qsobP+3gvV93MbhrI/52Q2tEqt+/g+F8IsLfbmhNXnEp7/+6Gx8vLx66qoUlsTgr0ZxcYfML++ObgWlOastwExMua0ZZufLqD9uB6pdsVJU3f9rBu7/sYlCXaF68uZ1JMoZTiQgv3Nye0jLl7aU7UVUeuqpFlX/unJJoVPUNEfkN6IXtTOYuVU12RluGe5l4eXNE4J/fb0eB1wbE4evt+TPfVW0J9oPfdjOoSzQv3dLerCtjVAlvL+GV2zrgJcI7v+yiTJVHr25ZpcnGoYlGRPyBCUBzYCPwgaqaea3Gf7mnT3ME4ZXvt5FXVMp7d3bG39fb6rCcprxceWbJZuas3Mfgro148eZ2JskYVcrLS3j5VtuXm/d/3U1eURlP39imyj6Hjj6jmQWUAH8A1wGtgQcd3IbhAe7u04ya/j48vXgTw6evZuqIBEL8fa0Oy+FKysp59NP1LF6XyvjLmvL4ta1Md5lhCS8v4cWb2xHk583UZXs5nl/Mq7fH4efj/B4FRyeaNqraHkBEpgGrHXx8w4MM696YEH8fHlm4nkFTVjLjri7UDfGc0iu5hSXc+3Ey/9qRzl+ubck9fczsMsNaXl62CQLhNf345/fbycovYdLQzgT6ObeunqNT2b8L7JguM6Mi+ndswEcjEkg5lkf/9/70mEKch7IKGDB5Bct2ZfDyre1NkjFchohwT5/m/OPW9izblcGynRnOb9ORF/KISBmQd/IhEADk2++rql50EScRCQc+AWKAFGCgqh4/w36NgKlANLbF1q5X1ZRzHTshIUETExMvNjTDAbak5jB61hqyC0p4e1AnrmpT1+qQLtr6A1mMmZ1IYXEZk4bG0yvWlJUxXFNKRh4xdYIu+vkikqSqCefbz6FnNKrqraoh9luwqvqccr+ylQIfB5aqaiyw1P74TGYDr6pqa6ArYBZGcQNt6oeweOIlxEbWZNycRN74cbvL1GmqKFVl3qp9DJi8gho+Xnx+T0+TZAyXVpkkcyHcaV5pf2yTDbD/vPn0HUSkDeCjqj8BqOoJe901ww1EhvizYFwPbuvckHd+2cWwaatIz3WPys/5xaU8snA9f/tiEz2a1eare3vRom6w1WEZhktwp0RTV1XTAOw/z7RmaQsgy76iZ7KIvCoiZ5w3KyLjRCRRRBLT09OdGLZxIQL8vHltQBz/vK0DSfuOc8M7f7j8ap3rDmRx07vL+GLdIR7q24IZI7tQK8gsv2QYJ7lUohGRn0Vk0xlu/St4CB+gN/Ao0AVoCow8046q+qGqJqhqQkREhEPiNxxnYJdovpx4CaEBvtw1Yw1/+Ww9OYWutZhTcWk5r/+4ndsmLSe/uIw5o7rxQN9Yc42MYZzGpdaKVdW+Z/udiBwRkShVTRORKM489nIQSFbVPfbnfAl0x5S/cUuto0L46r5evL10J1P+tZs/dmbw5A1tuL59PcuvRVm+K4Nnv9rMjiMnuD2+IU/d2IbQAM+7DsgwHMGlzmjOYwkwwn5/BLD4DPusAWqJyMlTlCuALVUQm+Ek/r7e/PXaVnx+d09CA3yZ+PFa7piy0rJp0Acy87l7bhJ3Tl1FQUkZU4cn8NqAOJNkDOMcHDq92ZlEpDawEGgE7AcGqGqmiCQAE1R1jH2/q4DXsU2pTgLGqWrxuY5tpje7h7JyZcGa/bz+4w6O5xdzbdt63NOnOe0bhjq97ZSMPD74bReL1h7C19uLiZc3Y0zvph5dOscwzqei05vdJtE4k0k07iW7oISPft/DrBUp5BaW0ju2DkO6NeKKVnUdWk6jrFxZvjuDBWsO8N3GNHy9vRjctRHjL2tKVGiAw9oxDHdlEs0FMInGPeUWljBv1X6mL9vL0dwiwgJ96RdXn76t69IlJpwAvws/2ygpK2ftvuP8tiOdJetSOZRVQGiAL3d0iWZM7yZEBntOiRzDqCyTaC6ASTTurbSsnD92ZfB50kF+3HKE4tJy/Ly96Nw4jLb1Q2keWZOmdYKoXdOPoBo+BPr6UFRaRk5hKdkFJaRk5LHjaC7bD+eSmHKcE0WleHsJPZvV5o4u0fRtXdd0kRnGGVQ00bjUrDPDuBg+3l5c3jKSy1tGkl9cypqU4/y5K4MVu48xb9U+CkvKz3sMP28vmkYE0a9jfS6NjaBn89oeWU3aMKxgEo3hUQL9fLisRQSXtbBNPCwvVw5lFbAnI4/sghLyikrJKyqlhq83If4+hPj7Eh0eSEztQHyqwQJshmEFk2gMj+blJUSHBxIdHmh1KIZRbZmvcIZhGIZTmURjGIZhOJWZdQaISDqw7yKfXgdw/spBrsW85urBvObqoTKvubGqnrdYpEk0lSQiiRWZ3udJzGuuHsxrrh6q4jWbrjPDMAzDqUyiMQzDMJzKJJrK+9DqACxgXnP1YF5z9eD012zGaAzDMAynMmc0hmEYhlOZRGMYhmE4lUk0lSAi14rIdhHZJSKPWx2Po4lItIj8KiJbRWSziDxg3x4uIj+JyE77z1pWx+poIuItIski8rX9cRMRWWV/zZ+IiJ/VMTqSiISJyGciss3+fvfw9PdZRB6yf643ich8EfH3tPdZRKaLyFER2XTKtjO+r2Lzjv3v2QYR6eyoOEyiuUgi4g28D1wHtAEGi0gba6NyuFLgEVVtDXQHJtpf4+PAUlWNBZbaH3uaB4Ctpzx+BXjT/pqPA6Mticp53ga+V9VWQBy21+6x77OINADuBxJUtR3gDQzC897nmcC1p2072/t6HRBrv40DJjkqCJNoLl5XYJeq7rEvFb0A6G9xTA6lqmmqutZ+PxfbH58G2F7nLPtus4CbrYnQOUSkIXADMNX+WIBElbjVAAAgAElEQVQrgM/su3jUaxaREOBSYBqAqharahYe/j5jKyocICI+QCCQhoe9z6r6O5B52uazva/9gdlqsxIIE5EoR8RhEs3FawAcOOXxQfs2jyQiMUAnYBVQV1XTwJaMgEjrInOKt4C/ACcXsqkNZKlqqf2xp73XTYF0YIa9u3CqiAThwe+zqh4CXgP2Y0sw2UASnv0+n3S299Vpf9NMorl4coZtHjlXXERqAp8DD6pqjtXxOJOI3AgcVdWkUzefYVdPeq99gM7AJFXtBOThQd1kZ2Ifl+gPNAHqA0HYuo5O50nv8/k47XNuEs3FOwhEn/K4IZBqUSxOIyK+2JLMPFVdZN985OQptf3nUavic4JLgH4ikoKtO/QKbGc4YfYuFvC89/ogcFBVV9kff4Yt8Xjy+9wX2Kuq6apaAiwCeuLZ7/NJZ3tfnfY3zSSai7cGiLXPUvHDNpC4xOKYHMo+NjEN2Kqqb5zyqyXACPv9EcDiqo7NWVT1CVVtqKox2N7TX1R1CPArcLt9N097zYeBAyLS0r7pSmALHvw+Y+sy6y4igfbP+cnX7LHv8ynO9r4uAYbbZ591B7JPdrFVlqkMUAkicj22b7vewHRVfdHikBxKRHoBfwAb+c94xf9hG6dZCDTC9h92gKqePuDo9kSkD/Coqt4oIk2xneGEA8nAUFUtsjI+RxKRjtgmP/gBe4C7sH0R9dj3WUSeA+7ANrsyGRiDbUzCY95nEZkP9MG2FMAR4BngS87wvtoT7nvYZqnlA3epaqJD4jCJxjAMw3Am03VmGIZhOJVJNIZhGIZTmURjGIZhOJXP+XfxfHXq1NGYmBirwzAMw3ArSUlJGaoacb79TKIBYmJiSEx0yOQKwzCMakNE9lVkP9N1ZhiGYTiVOaMxDA9QVq4cySkkLbuAopJySsqVclXCAnyJCK5BnZo18Pf1tjpMo5oyicYw3Iyqsjs9j9V7M1mTksm6A1kcPJ5PSdm5r4lrUieI9g1C6dAwlF6xdWhZNxjbNXqG4Vwm0RiGm9iTfoIl61P5an0qu9PzAKhT04/4xrW4pm09osMDqB8WQICvN77egoiQlV9Mem4RadmFbE3LITElkyXrbeWrGoUHclWbutzauQFt64da+dIMD2cSjWG4MFXltx3pTP1jD3/uOoYIdGsSzshLmnBJs9o0qRN0wWclR3IKWbr1KD9tOcycFfuYtmwv8Y1rMbxHY65rF4Wfjxm6NRzLlKABEhIS1Mw6M1yJqvLtxsO89fMOdh49Qb0Qf0b0jOGWTg2oF+rvsHay80v4NOkAc1fuI+VYPtHhATxwZQtu6dQAby/TrWacm4gkqWrCefczicYkGsO1JKZk8uK3W0nen0WLujWZcFkzbuxQ36lnGuXlym87jvLmTzvZeCibZhFBPHFda/q2qeu0Ng33ZxLNBTCJxnAFmXnFPP/1Fr5IPkTdkBo8clVLbotvWKVnFqrKD5uP8NqP29l19ARXt6nLM/3a0iAsoMpiMNyHSTQXwCQaw0qqyjcb03hm8WayC0q4u08z7u7TjEA/64ZQS8rKmbZsL2/9vAMvEf5yTUtG9Iwxs9SM/2ISzQUwicawSm5hCU8s2sjXG9Lo0DCUV27rQOuoEKvD+rcDmfk8tXgTv21P57IWEbw6oAORwY4bIzLcW0UTjZleYhgW2XAwixveWcZ3mw7z2DUtWXR3T5dKMgDR4YHMGNmF5/u3ZeWeY1z31h/8ut2TVnQ2qoJJNIZhgTkr93HbpOWUlpXzybjuTLy8OT7ervnfUUQY1iOGr+/rRURwDUbNXMN7v+zE9IYYFeWan2zD8FAlZeU8+eVGnvpyE71jI/j2gd4kxIRbHVaFxNYN5ot7LqFfXH1e+3EHd89dy4miUqvDMtzAORONiHiLyKtVFYxheLLjecUMn7aauSv3M+GyZnw0PIGwQD+rw7ogAX7evHVHR568oTU/bjnM7ZOWk5ZdYHVYhos7Z6JR1TIgXsxUE8OolIPH87lt8nKS9h3njYFxPH5dK7e9IFJEGNO7KbNGdeXg8QJueX852w7nWB2W4cIq0nWWDCwWkWEicuvJm7MDMwxPse1wDrdNWk5GbhFzx3Tj1s4NrQ7JIXrHRrBwfA8UZcCkFSzflWF1SIaLqkiiCQeOAVcAN9lvNzqicRG5VkS2i8guEXn8DL+vISKf2H+/SkRiTvndE/bt20XkmlO2p4jIRhFZJyJmzrJhqTUpmQycvAKAhRN60LWJe4zHVFSb+iF8cc8lRIX5M3LmGn7ecsTqkAwXZNl1NCLiDewArgIOAmuAwaq65ZR97gE6qOoEERkE3KKqd4hIG2A+0BWoD/wMtFDVMhFJARJUtcJfr8x1NIYzLN+dweiZiUSF+jN7dFca1gq0OiSnOZ5XzIgZq9mSmsNbgzpyY4f6VodkVAGHXUcjIv4iMlFEPhCR6SdvDoixK7BLVfeoajGwAOh/2j79gVn2+58BV9rHi/oDC1S1SFX3ArvsxzMMl/DHznRGzVxDdHgAn4zv4dFJBqBWkB/zxnSjU6Mw7p+fzGdJB60OyXAhFek6mwPUA64B/gU0BHId0HYD4MApjw/at51xH1UtBbKB2ud5rgI/ikiSiIxzQJyGcUF+236U0bMSiakdxPyx3YkIrmF1SFUi2N+XWaO60rNZHR77bD1fJJtkY9hUJNE0V9WngDxVnQXcALR3QNtnmnJzej/e2fY513MvUdXOwHXARBG59IyNi4wTkUQRSUxPT69ozIZxTst3ZTB+ThKxkTWZP7Y7tWtWjyRzUqCfD1NHJNCjaW0eWbj+34usGdVbRRJNif1nloi0A0KBGAe0fRCIPuVxQ+D0T+W/9xERH3vbmed6rqqe/HkU+IKzdKmp6oeqmqCqCREREZV+MYaRtC+TMbMTaVw7kDmju1EryL2ukXEUf19vpo5IIKFxOA99so7vNqZZHZJhsYokmg9FpBbwJLAE2AL80wFtrwFiRaSJiPgBg+zHP9USYIT9/u3AL2qbvbAEGGSfldYEiAVWi0iQiAQDiEgQcDWwyQGxGsY5bTyYzcjpa6gb4s/cMd0Ir6ZJ5qRAPx+m39WFuIah3L8gmT92ml6D6uy8iUZVp6rqcVX9XVWbqmqkqk6ubMP2MZd7gR+ArcBCVd0sIn8XkX723aYBtUVkF/Aw8Lj9uZuBhdiS3vfARPvFpXWBZSKyHlgNfKOq31c2VsM4lz3pJxgxYzUhAb7MG9PNVDe2q1nDhxl3daVZRE3Gz0kief9xq0MyLHLe6c0i8hLwT1XNsj+uBTyiqk9WQXxVwkxvNi7WkZxCbv1gOYUlZXx2d0+a1AmyOiSXczS3kAGTV5BdUMLC8T1oUTfY6pAMB3HkMgHXnUwyAKp6HLi+MsEZhifILihhxPTVZOUXM/OuribJnEVksD9zRnXDz9uL4dNWm9po1VBFEo23iPx76oyIBADVayqNYZymqLSMcbMT2Z1+gsnD4mnfMNTqkFxao9qBzBrVlRNFpdw1Yw05hSXnf5LhMSqSaOYCS0VktIiMAn7iPxdRGka1o6r85bMNrNqbyWsD4ugda2YtVkTrqBAmDe3MrqMnmDAnieLScqtDMqpIRSYD/BN4AWgNtAWet28zjGrp9R93sHhdKo9d05L+HU+/xtg4l96xEbxyWweW7z7GXz/fYBZPqyZ8KrKTfeaWmb1lVHufrNnPe7/uYlCXaO7p08zqcNzSbfENOZRVwBs/7SCmdhAP9I21OiTDySqUaAzDsBXJ/NsXm+gdW4fnb26HWabp4t13RXNSMvJ48+cdNIkIol+cKcLpycxSzoZRAXsz8rh77lqa1Ani/SGd8fU2/3UqQ0R4+bb2dI0J59FP15O0z1xj48nO+r9FRJbaf75SdeEYhuvJzi9h9Mw1eAlMG9GFEH9fq0PyCDV8vJk8LJ6oUH/Gz0nkUJaZ9uypzvW1LEpELgP6iUgnEel86q2qAjQMK5WWlTPx47UcOJ7PlGEJNKrt2eX+q1p4kB/TRnShqKScMbMSyS8utTokwwnOlWiexlbypSHwBvD6KbfXnB+aYVjvhW+2smxXBi/e0t7jVsd0Fc0ja/LOnZ3YfjiHRxaup7zczETzNGdNNKr6mapeh638zOWn3a6owhgNwxIL1xxg5vIURl3ShIEJ0ed/gnHRLm8ZyRPXtea7TYd5e+lOq8MxHOy8s85U9Xl7kcuT67r8pqpfOzcsw7BWYkomf/tyI71j6/B/17eyOpxqYUzvJmw/ksvbS3fSOiqYa9tFWR2S4SAVWcr5ZeABbJWStwAP2LcZhkdKyy5gwty11A8L4N3BnfAxM8yqhIjwws3tiIsO4+GF69l+2BEL+RquoCL/g24ArlLV6ao6HbjWvs0wPE5hSRkT5iRRUFzKR8MTCAus3uvKVDV/X2+mDI0nqIYP4+YkkpVfbHVIhgNU9Kta2Cn3TfVAwyOpKk9+uYn1B7N5fWBHU87eIvVC/Zk8tDOpWQXcNz+ZMjM5wO1VJNG8DCSLyEwRmQUkAS85NyzDqHqzV+zjs6SD3HdFc65tV8/qcKq1+MbhPN+/HX/szOC1H7dbHY5RSRWZDDBfRH4DugAC/FVVDzs7MMOoSqv3ZvL811u4olUkD/VtYXU4BjCoayM2HMpm0m+7aVc/lBs6mMkB7qqiRTXTgCVOjsUwLHE4u5B75iURHR7Im3d0xMvL1DBzFc/c1IataTk89tl6mkfWpGU9053pjsx0GqNaKyot4+55SeQXlzFlWDyhAaa8jCup4ePNZPvkgPFzEskuMAumuSNLE42IXCsi20Vkl4g8fobf1xCRT+y/XyUiMaf87gn79u0ick1Fj2kYp3ruqy0k78/itQFxZvDfRdUN8WfSkM4cPF7Aw5+sM5UD3FBFrqN5TUTaOrphEfEG3geuA9oAg0WkzWm7jQaOq2pz4E3gFftz2wCDsC3Edi3wgYh4V/CYhgHY1pb5eNV+JlzWjOvbm/5/V5YQE87TN7Vh6bajvPvLLqvDMS5QRc5otgEf2s8oJoiIo6Y3dwV2qeoeVS0GFgD9T9unP/9ZNvoz4EqxLQLSH1igqkWquhfYZT9eRY7pMAcy81m87pCzDm840foDWTy1eDO9mtfhsWtaWh2OUQHDujfm1s4NeGvpDn7ZdsTqcIwLUJGlnKeq6iXAcCAG2CAiH4vI5ZVsuwFw4JTHB+3bzriPqpYC2UDtczy3IscEQETGiUiiiCSmp6df1At48+cdPLxwPSv3HLuo5xvWOHaiiLvnJhFRswbvDO6Etxn8dwsiwku3tKdNVAgPLFhHSkae1SEZFVShMRp7l1Qr+y0DWA88LCILKtH2mf53n975erZ9LnT7/25U/VBVE1Q1ISIi4pyBns2z/drSODyQez9eS1q2WUvDHZSWlXPf/GSO5RUzZVg84UHmyn934u9rmxzg7SWMn5NEXpFZVsAdVGSM5g1s3WfXAy+paryqvqKqNwGdKtH2QeDUkrgNgdSz7SMiPtiqEmSe47kVOabDhPj78uHweAqKy7h77lqKSsuc1ZThIK98v43lu4/x4i3tadfAFLlwR9Hhgbw7uBM7j+by1883oGomB7i6ipzRbALiVHW8qq4+7XddK9H2GiBWRJqIiB+2wf3Tr9VZAoyw378d+EVtn6olwCD7rLQmQCywuoLHdKjmkcG8PjCOdQeyeHbJFmc2ZVTSkvWpfPTHXob3aMzt8Q2tDseohN6xETx6TUu+3pDG1D/2Wh2OcR4VSTRDVDX/1A0nl3lW1eyLbdg+5nIv8AOwFVioqptF5O/2ZQkApgG1RWQX8DC2hdhQ1c3AQmzVpL8HJqpq2dmOebExVtS17aK4u08z5q/ez/zV+53dnHERtqbl8NfPNpDQuBZP3mAmInqCuy9rxnXt6vHyd1tZvivD6nCMc5CznXaKiD8QCPwK9OE/4x8hwHeq2roqAqwKCQkJmpiYWKljlJUrI2esZtWeTBaM707nRrUcFJ1RWdn5JfR7fxkFxWV8fX8vIoP9rQ7JcJATRaXc8v6fZJwo4qv7etGwlllquyqJSJKqJpxvv3Od0YzHVkCzFbDWfj8JWIztWhXjFN5ewruDO1E3tAZ3z03iaG6h1SEZ2L4A3LcgmdSsAiYN7WySjIepWcOHKcPiKS1Xxs9JorDEjJO6onMt5fy2qjYBHlXVJqfc4lT1vSqM0W2EBfoxZWgC2QUlTJy3luLScqtDqvZe+3E7v+9I57l+7YhvHG51OIYTNI2oyduDOrIlLYcnFm00kwNc0FkTjYhcYb97SERuPf1WRfG5nTb1Q/jn7XGsSTnO3792+vCQcQ7fbEhj0m+7Gdy1EXd2a2R1OIYTXdGqLg/1bcEXyYeY/meK1eEYpzlX9ebLgF+Am87wOwUWOSUiD9Avrj6bU7OZ8q89tK0fyuCu5o9cVdt22Fbxt3OjMJ7tZwb/q4N7L2/OpkPZvPjNFlrWDaZXbB2rQzLszjoZoDpxxGSA05WVK6NmrmH57gzmj+1OQozptqkqmXnF9HtvGSVl5Xx1by8iQ8y4THVxoqiUWz/4kyM5RSy59xIa1w6yOiSP5ojJACcP9JKIhJ3yuJaIvFDZAD2dt5fwzqBONAgLYMLctaRmmcoBVaGkrJx75iVxNLeIKcMSTJKpZmrW8OGj4ba/e+NmJ3HCVA5wCRW5juY6Vc06+UBVj2OrEmCcR2igLx8NT6CwpIyxsxPJLzYfemd7/ustrNyTyT9ubU/H6LDzP8HwOI1rB/HenbbKAQ+ZZQVcQkUSjbeI1Dj5QEQCgBrn2N84RWzdYN4d3IktaTk89qkpl+FMc1fuY/aKfYzt3YRbO5sr/6uz3rERPHVjG37acoTXf9pudTjVXkUSzVxgqYiMFpFRwE/8p3S/UQGXt4rkieta8c3GNN5ZatbScIbluzJ4ZslmLm8ZwePXecy1xEYljOwZw+Cu0bz/626znIfFzjXrDABV/aeIbAD62jc9r6o/ODcszzO2d1O2Hz7Bmz/voGlEEDfF1bc6JI+xJ/0Ed89bS9M6Qabsv/FvIsJz/dqxOz2Pxz7bQHR4oKnYYZGKLuWcDPwL+M1+37hAIsJLt7ajS0wtHvl0PUn7jlsdkkfIyi9mzKxEvL2EaSO6EOzva3VIhgvx8/Fi8tB46oX4M252Igcy88//JMPhKjLrbCC2ysi3AwOBVSJyu7MD80Q1fLyZMizBfOgdpKi0jPFzkjh4vIDJQ+NpVNvUuTL+V3iQH9NHdqG4tJxRM9eQU1hidUjVTkXOaP4GdFHVEao6HNvSAE85NyzPdfJDX1Jm+9BnF5gP/cVQVf762QZW7c3k1QEd6NrEXKdknF3zyJpMHhrP3ow8Js5bS0mZKQ9VlSqSaLxU9egpj49V8HnGWZz80Kccy2P8nESzYNpFePOnHXy5LpVHr25B/45nXK3bMP5Lz+Z1eOnW9vyxM4O/fWFqolWliiSM70XkBxEZKSIjgW+Ab50blufr2bwOr94ex8o9mTz66QYz1/8CLFi9n3d+2cXAhIZMvLy51eEYbmRgQjQPXBnLwsSDvPnzTqvDqTYqMuvsMRG5DbgE25o0H6rqF06PrBq4uVMDUrML+Of326kf6s8T15tpuefz4+bD/N8XG7m0RQQv3tIeETPDzLgwD/aN5XB2Ie8s3Um9EH9TcLUKnDfRAKjq58DnTo6lWrr7smakZRUy5fc9RATXYEzvplaH5LISUzK5b34y7RuEMmlIZ3y9TQ+uceFEhBduacfR3EKe/HIjdWr6cXXbelaH5dHOtUxArojknOGWKyI5VRmkJxMRnu3XlhvaR/HCN1tZmHjA6pBc0vbDuYyauYb6YQFMH9mFoBoV+o5kGGfk6+3F+0M606FhGPfOT2b5brMUtDOda+GzYFUNOcMtWFVDKtOoiISLyE8istP+84xXUYnICPs+O0VkxCnb40Vko4jsEpF3xN5/IiLPisghEVlnv7lFTTZvL+GNO+LoHVuHxz/fwPebDlsdkkvZm5HHkKmrCPDzZvaortSuaSogGZUX6OfDzLu60KR2EGNnJbLuQNb5n2RclAr1PYhILxG5y36/jog0qWS7jwNLVTUWWGp/fHqb4cAzQDdsU6qfOSUhTQLGAbH227WnPPVNVe1ov7nNpAXbNTbxxEWHcf/8ZP61I93qkFzCweP5DPloJeWqzBvTjehwc62M4ThhgX7MGW378jJyxmq2HTadNc5QkQs2nwH+Cjxh3+SHrf5ZZfTnP/XSZgE3n2Gfa4CfVDXTXjH6J+BaEYkCQlR1hdrmJ84+y/PdTqCfDzNGdqF5ZE3GzU5k2c7qfTp/JKeQIVNXkVtUyuxRXWkeGWx1SIYHigzxZ96YbtTw8WLIR6vYcSTX6pA8TkXOaG4B+gF5AKqaClT2f3xdVU2zHy8NiDzDPg2AUwcsDtq3NbDfP337SfeKyAYRmX62LjlXFhbox9wx3WhSJ4gxs9dU277jw9mFDPpwJRm5Rcy8qyvtGoRaHZLhwaLDA5k/tjveXsKdH61kp0k2DlWRRFNsP3NQABGp0JJ1IvKziGw6w61/BWM707xVPcd2sHWpNQM6AmnA6+eIb5yIJIpIYnq6a3VThQf5MW9MNxqFBzJ6ZiLLd1WvZJOaVcAdH64gPbeI2aO7Et/Y7b4vGG6oaURNPh7bHRFh8Eer2HXUJBtHqUiiWSgiU4AwERkL/Ax8dL4nqWpfVW13htti4Ii9Cwz7z6NnOMRBIPqUxw2BVPv2hmfYjqoeUdUyVS23x9j1HPF9qKoJqpoQERFxvpdT5WrXrMG8Md1pFB7IyJlrWLr1iNUhVYkDmfkM+nAlmSeK7UnGlJYxqk7zyJrMH9sdERg4ZSWbDmVbHZJHOG+iUdXXgM+wXUfTEnhaVd+tZLtLgJOzyEYAi8+wzw/A1falo2sBVwM/2LvackWku3222fCTzz+ZvOxuATZVMk5LRQTXYMG47rSqF8z4OUl8tT7V6pCcavvhXG6fvJys/GLmjOlmSroblmgeWZNPx/cgwNebwR+uZPXeTKtDcnvnuo7mPRHpCaCqP6nqY6r6qKr+5IB2/wFcJSI7gavsjxGRBBGZam8zE3geWGO//d2+DeBuYCqwC9gNfGff/k/7tOcNwOXAQw6I1VK17N1onRvV4v4FycxekWJ1SE6RmJLJgMnLAfh0Qk+zDLNhqZg6QXw6oQcRITUYPn0Vv2zzzB6FPeknqqQdOVthORF5ABgERAGfAPNVdV2VRFXFEhISNDEx0eowzqmguIz75q/l561HGXdpUx6/thVeHrLA1w+bD/PAgmSiQgOYPaqrmcJsuIxjJ4oYOWMNm1Ozea5fW4b1iLE6JIdQVWb8mcIL32xh0tB4rrnIyggikqSqCefb71wXbL6tqj2Ay4BMYIaIbBWRp0WkxUVFZVy0AD/bWjbDezTmw9/3cO/8tRSWuHfVZ1Vl0m+7mTA3iZZ1g/l0Qg+TZAyXUrumrfv6ilaRPLV4My98vYUyNy+AW1JWzpNfbuLvX2+hb+u69I6t4/Q2z3pGc8adRToB04EOqurttKiqmDuc0Zykqkz9Yy8vfbeVNlEhTB4a75Z/nItKy3hi0UYWrT3EjR2ieG1AHP6+HvORMjxMWbny/NdbmLk8hctbRvDWHZ0IDXS/1Vyz8ou5b34yf+zMYMJlzfjLNS0r1TNS6TOaUw7kKyI3icg8bGMhO4DbLjoyo1JEhLGXNmXq8AT2Z+Zz03vL+GOna03PPp/9x/K5fdIKFq09xEN9W/Du4E4myRguzdvLVpPw+f5tWbYrg5veW8bmVPeakbbuQBY3vLOMlXuO8c/bO/D4dVXX/X6uMZqrgMHADdiWcl4AfKmqeVUSWRVypzOaU+3NyGPCnCR2Hs3l3itiue+K5i5f0fi7jWn85bMNiMCrA+Iuum/YMKyStO84E+et5Xh+Mc/2a8ugLtEuvVyFqjJreQovfruVyGB/PhjSmTgHTbap6BnNuRLNr8DHwOenzPbySO6aaADyi0t58stNLFp7iLiGobx5R0eaRtS0Oqz/kVNYwsvfbmX+6gPERYfx3uBObtnlZxgAGSeKeGBBMn/uOsaVrSJ5+bb2RAb7Wx3W/zicXcgTizbw6/Z0rmwVyesD4wgL9HPY8SudaKoTd040J32zIY3/+2IjxaXlPHJ1C0b2jMHHRc5uft1+lP9btJEjOYWMvbQpj1zVEj8f14jNMC5Webkyc3kKr3y/jUA/b57r346bOkS5xNmNqvL52kM899VmSsrK+eu1rRjRI8bhXWUm0VwAT0g08N/fXlrVC+b5m9vRJca6K+sPZObzj++38c2GNGIja/LqgDhzfYzhcXYeyeWRT9ez4WA2PZrW5rn+bWlR17oCsJtTs/n7V1tYtTeTLjG1ePX2OGLqVKhy2AUzieYCeEqiAds3mR82H+HvX20mNbuQG9pH8WDfWGKr8IOfU1jCpN92M23ZXrwEJlzWjLv7NKOGjxnwNzxTWbkyf/V+Xv1hO3lFpdzZrRH39GlOvdCq6047nF3I20t3sGDNAWoF+vHwVS24s2sjpw74m0RzATwp0ZyUX1zKZPsf+/ySMvrF1WfCZc1oHVWpNevO6XB2ITP+3Mu8Vfs5UVTKrZ0b8Ng1LYkKDXBam4bhSjLzinn9x+18suYAXiLc0SWa8Zc1pWEt541H7s3IY8q/dvP52oOowoieMdx/ZSyhAc6ffm0SzQXwxERzUmZeMR/+vodZy1MoKCmjc6Mw7uzWmOvb1yPQr/LLIZeUlbNsZwZfJB/iu01plJUrN3Soz4TLmtK2vintb1RPBzLz+eC33XyaeIAyVS6NjWBw12iubF3XITNDC0vK+HHLERatPcjvO9Lx8fbijoRoxl3atEon2ZhEcwE8OdGclJVfzGdJB/l49X72pOfh5+NFz2a1ubJVJN2a1qZpnaAKTx5IzSpg5Z5jrNh9jKXbjpKZVzjWLJoAAAcTSURBVExYoC/94+ozuldTGtU2s8kMA+BQVgGfrDnAp4kHSMsuJNjfh96xdejTIpIezWrTsFZAhSYPqCr7juXz5+4Mlu86xu870sktKqV+qD+3xTdkWI/Glsx6M4nmAlSHRHOSqrJ6byY/bjnC0q1HSDmWD0ANHy9aRYXQKDyQ2kF+1Ar0w9dHKC4tp6i0nPTcIlIy8kg5lk/GiSLg/9u7/9i6yjqO4+9Pb1vXdR0b3bTaAVtJN1w0MAKkDIQJ/AFCHEaNGlRCNMZEBY3GoP+If5hgQlQIhoTwQ0wMPzKILv6BGFzEf5wTp4yxgTDUdXRbh3ZdR6Vd++WP85TdLC1j7T09t6efV9Lc+5yeJt8n33vv957nefocOK2liUu7l3H9eZ1cvnq5V5KZTWFsPHjmpX5+t3M/W148yIHB7D206D2NrOlo46z2hSxpaea0liaaGxsYHjnG8OgYrw+N8Mqho+zpH+LI/48B0LF4AR/pXsYn1nXS09Ve6J6HLjSnYD4VmmoRwauHjvKP3gF27htk52uD9B0e5vWjI2+/qAGaKw0sbW1iZXsrK9tbWdPRRk9XO+d0tJVmY0+z2RIR7Oo7wt/3DrB7/yC7+46wb2CYw8OjDL15/H3X0lRh6cImVi1vpWvZIlZ3tLH+7Gz0oR6WUIMLzSmZr4XmnYwcG2c8guZKg4uJ2SwZHRtndGycBY2VOfG+e7eFZuazwVZKHgYzm31NlYa630ZqOsrXIzMzqysuNGZmlivP0QCS+oF/T/PPlwGHahjOXOA+zw/u8/wwkz6fFRHLT3aSC80MSfrru5kMKxP3eX5wn+eH2eizh87MzCxXLjRmZpYrF5qZu7foAArgPs8P7vP8kHufPUdjZma58hWNmZnlyoVmBiRdLelFSS9LurXoeGpN0hmStkjaJWmnpFvS8dMl/V7SP9Pj0qJjrTVJFUnbJf02tVdJ2pr6/Kik2t14vQ5IWiJpk6TdKd8Xlz3Pkr6VXtfPS3pY0oKy5VnSA5IOSnq+6tikeVXmrvR59pyk82sVhwvNNEmqAD8HrgHWAp+TtLbYqGruGPDtiPgg0AN8LfXxVuDpiOgGnk7tsrkF2FXV/jHw09Tn/wFfKiSq/NwJPBkR5wDnkvW9tHmW1AncDFwQER8CKsBnKV+efwFcfcKxqfJ6DdCdfr4C3FOrIFxopu8i4OWI2BMRI8AjwMaCY6qpiOiLiL+l50fIPnw6yfr5UDrtIeD6YiLMh6QVwLXAfakt4ApgUzqlVH2WtBi4DLgfICJGImKAkueZbK/HFkmNwEKgj5LlOSKeAf57wuGp8roR+GVk/gwskfT+WsThQjN9ncDeqnZvOlZKklYC64CtwPsiog+yYgS8t7jIcvEz4LvAeGq3AwMRMbGHe9ly3QX0Aw+m4cL7JLVS4jxHxD7gDuA/ZAXmMPAs5c7zhKnymttnmgvN9E22h3cpl/BJWgQ8DnwzIgaLjidPkq4DDkbEs9WHJzm1TLluBM4H7omIdcBRSjRMNpk0L7ERWAV8AGglGzo6UZnyfDK5vc5daKavFzijqr0CeK2gWHIjqYmsyPwqIp5Ihw9MXFKnx4NFxZeDS4CPS/oX2XDoFWRXOEvSEAuUL9e9QG9EbE3tTWSFp8x5vgp4NSL6I2IUeAJYT7nzPGGqvOb2meZCM33bgO60SqWZbCJxc8Ex1VSam7gf2BURP6n61WbgxvT8RuA3sx1bXiLiexGxIiJWkuX0DxFxA7AF+FQ6rWx93g/slbQmHboSeIES55lsyKxH0sL0Op/oc2nzXGWqvG4GvphWn/UAhyeG2GbK/7A5A5I+RvZttwI8EBE/KjikmpJ0KfAnYAfH5yu+TzZP8xhwJtkb9tMRceKE45wnaQPwnYi4TlIX2RXO6cB24PMR8WaR8dWSpPPIFj80A3uAm8i+iJY2z5J+CHyGbHXlduDLZHMSpcmzpIeBDWQ7NB8AfgD8mknymgru3WSr1N4AboqImtx62IXGzMxy5aEzMzPLlQuNmZnlyoXGzMxy5UJjZma5cqExM7NcNZ78FDOrFUntZBsZAnQAY2TbvwC8ERHrCwnMLEde3mxWEEm3AUMRcUfRsZjlyUNnZnVC0lB63CDpj5Iek/SSpNsl3SDpL5J2SDo7nbdc0uOStqWfS4rtgdnkXGjM6tO5ZPfE+TDwBWB1RFxE9t/730jn3El275QLgU+m35nVHc/RmNWnbRP7TEl6BXgqHd8BfDQ9vwpYm+0cAsBiSW3p3kFmdcOFxqw+Ve+vNV7VHuf4+7YBuDgihmczMLNT5aEzs7nrKeDrE420MaZZ3XGhMZu7bgYukPScpBeArxYdkNlkvLzZzMxy5SsaMzPLlQuNmZnlyoXGzMxy5UJjZma5cqExM7NcudCYmVmuXGjMzCxXLjRmZpartwBq/AuXbPIlaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import cos\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def sim_car(x, x_dot, acceleration, x_lims = (-1.2,0.5), x_dot_lims = (-0.07,0.07)):\n",
    "    ## Compute velocity within limits\n",
    "    x_dot_prime = x_dot + 0.001 * acceleration - 0.0025 * cos(3 * x)\n",
    "    if(x_dot_prime < x_dot_lims[0]): x_dot_prime = x_dot_lims[0]\n",
    "    if(x_dot_prime > x_dot_lims[1]): x_dot_prime = x_dot_lims[1]\n",
    "        \n",
    "    ## Now update position\n",
    "    x_prime = x + x_dot_prime\n",
    "    if(x_prime < x_lims[0]): x_prime = x_lims[0]\n",
    "    if(x_prime > x_lims[1]): x_prime = x_lims[1]\n",
    "      \n",
    "    ## At the terminal state or not and set reward\n",
    "    if(x_prime >= x_lims[1]): \n",
    "        done = True\n",
    "        reward = 100.0\n",
    "    else: \n",
    "        done = False\n",
    "        reward = -1.0\n",
    "        \n",
    "    return(x_prime, x_dot_prime, done, reward)    \n",
    "        \n",
    "def initalize_car(x_lims = (-0.6,-0.4)):\n",
    "    ## Find random start for car\n",
    "    return(nr.uniform(x_lims[0],x_lims[1]))\n",
    "\n",
    "## Test the function\n",
    "a = -0.0\n",
    "x_dot = [0.0]\n",
    "x = [initalize_car()]\n",
    "for i in range(100):\n",
    "    x_temp, x_dot_temp, done, reward = sim_car(x[i], x_dot[i], a)\n",
    "    x.append(x_temp)\n",
    "    x_dot.append(x_dot_temp)\n",
    "    \n",
    "def plot_car(x, x_dot):    \n",
    "    ## Plot car position\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(211)    \n",
    "    ax1.plot(x)\n",
    "    ax1.set_ylabel('Positon of car')\n",
    "    \n",
    "    ## PLot car velocity\n",
    "    ax2 = fig.add_subplot(212)  \n",
    "    ax2.plot(x_dot)\n",
    "    ax2.set_ylabel('Velocity of car')\n",
    "    ax2.set_xlabel('Time')\n",
    "    \n",
    "plot_car(x,x_dot)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no acceleration applied, the car oscillates back and forth. The motion is not damped since the simulator includes no friction term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NN Function Approximation for the Mountain Car Problem\n",
    "\n",
    "A general, but computationally intensive, solution to the mountain car problem can be obtained using **deep Q-Learning**. Here we use a neural network model as a function approximator for the action values, $\\hat{q}(S_{t}, A_{t}, w_{t-1})$.   \n",
    "\n",
    "The code in the cell below defines a simple neural network model to approximate the action values for the mountain car problems. A few key points include:\n",
    "- There are three input variables, the two state variables, position and velocity, along with the action. \n",
    "- A single hidden layer of 20 units is used. This is a rather spare representation, but is chosen for convenience of the demonstration rather than accuracy. \n",
    "- Since over-fitting is a constant problem with neural networks three regularization methods are applied, l2 regularization, dropout regularization and early stopping. \n",
    "- Since this is a regression problem, to approximate the numeric action value, the output layer consists of a single unit with linear activation. \n",
    "\n",
    "Execute this code to run the simple test case.\n",
    "\n",
    ">**Note:** The code shown in this notebook is intended to illustrate the basic concepts of deep Q-Learning. For more robust solutions you are advised to look at the contributed [keras-rl package](https://github.com/keras-rl/keras-rl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00162917]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import keras.utils.np_utils as ku\n",
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "def DL_model():\n",
    "    ## Define the Keras model\n",
    "    function_approx = models.Sequential()\n",
    "    function_approx.add(layers.Dense(3, activation = 'relu', input_shape = (3,), \n",
    "                                     kernel_regularizer=regularizers.l2(0.01)))\n",
    "    function_approx.add(Dropout(0.5)) # Use 50% dropout\n",
    "    function_approx.add(layers.Dense(20, activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    function_approx.add(Dropout(0.5)) # Use 50% dropout\n",
    "    function_approx.add(layers.Dense(1, activation = 'linear'))\n",
    "    function_approx.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])\n",
    "    ## Define the callback list for early stopping   \n",
    "    filepath = 'my_model_file.hdf5' # define where the model checkpoints are saved\n",
    "    callbacks_list = [keras.callbacks.EarlyStopping( #monitor = 'val_loss', patience = 1)\n",
    "            monitor = 'val_loss', # Use loss to monitor the model\n",
    "            patience = 1 # Stop after one step with lower accuracy\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath = filepath, # file where the checkpoint is saved\n",
    "            monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "            save_best_only = True # Only save model if it is the best\n",
    "        )\n",
    "    ]\n",
    "    return(function_approx)\n",
    "function_approx = DL_model()\n",
    "function_approx.predict(np.array([[0.1,0.1,0.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "function_approx.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below preforms greedy selection of the next action. The neural network is used to predict the action value for each possible action and the maximum is selected. Execute this code to run the simple test case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09761165877718599,\n",
       " -0.002388341222814015,\n",
       " False,\n",
       " -1.0061371222138404,\n",
       " -0.0068190247)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_Q_values(x,x_dot,actions,gamma,epsilon,online_model,target_model):\n",
    "    '''This function generates a sample state transiton and associtated \n",
    "    Q values using the current models'''\n",
    "    Q_target = []\n",
    "    ## Iterate over all actions to find Q values\n",
    "    for a in actions:\n",
    "        Q_target.append(target_model.predict(np.array([[x,x_dot,a]]))[0][0])\n",
    "    ## Find the next action using epsilon greedy algorithm\n",
    "    if(nr.uniform() <= epsilon): # take random aciton\n",
    "        max_index = nr.choice(range(len(actions)), replace = True)\n",
    "    else: # take greedy action\n",
    "        ## Find the action with max Q\n",
    "        max_index = np.argmax(Q_target)\n",
    "    ## Find Q from the online model for the the action selected \n",
    "    Q_online = online_model.predict(np.array([[x,x_dot,actions[max_index]]]))[0][0]\n",
    "    ## Find the next state and reward\n",
    "    x_prime, x_dot_prime, done, reward = sim_car(x, x_dot, actions[max_index])\n",
    "    ## update the Q target\n",
    "    Q_out = reward + gamma * Q_target[max_index]\n",
    "    return(x_prime, x_dot_prime, done, Q_out, Q_online) #, actions[max_index], max_index)\n",
    "\n",
    "## Simple test of the funciton using a random model for both online and target\n",
    "actions = [-1.0,0.0,1.0]        \n",
    "compute_Q_values(0.1,0.0,actions,0.9,0.05,function_approx,function_approx)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below execute a simple Q-Learning algorithm using the previously defined neural network model as the function approximator. Some important points for this algorithm are:\n",
    "1. An $\\epsilon$-greedy approach is used to select actions. \n",
    "2. The target action value,  $\\hat{q}(S_{t}, A_{t}, w_{t-1})$, used to train the neural network model is the 1-step bootstrapped reward estimate. \n",
    "\n",
    "Some additional details of the algorithm can be learned by reading the code comments. \n",
    "\n",
    "Execute this code for just 10 episodes and examine the results. This will take some time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model(online_model, target_model):\n",
    "  target_model.set_weights(online_model.get_weights())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]]\n",
      "\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def replay_buffer(new_cases, buffer, n_cases = 4096):\n",
    "    \"\"\"Function manages replay buffer as a numpy array with\n",
    "    maximum size of n_cases. Newest data is retained once\n",
    "    more than n_cases available\"\"\"\n",
    "    if(buffer.shape[0] <= n_cases): \n",
    "        ## still growing buffer so append old cases to new\n",
    "        out = np.append(new_cases, buffer, axis = 0)\n",
    "    else: ## Delete some rows and add the new at the top\n",
    "        ## Create a mask for the rows we wish to keep or delete\n",
    "        del_rows = n_cases - new_cases.shape[0] + 1\n",
    "        mask = np.ones(buffer.shape[0], dtype=bool) \n",
    "        mask[del_rows:] = False\n",
    "        ## Append old cases to new \n",
    "        out = np.append(new_cases, buffer[mask,:], axis = 0)\n",
    "    return(out)\n",
    "\n",
    "b = np.zeros((3,2))\n",
    "add = np.ones((1,2))\n",
    "for _ in range(6):\n",
    "    b = replay_buffer(add, b, 4)\n",
    "    print(b)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.32889613, -0.03659458,  0.        , -1.        ],\n",
       "        [-0.29230154, -0.03499575,  0.        , -1.        ],\n",
       "        [-0.25730579, -0.03320431,  0.        , -1.        ],\n",
       "        [-0.22410148, -0.03124834,  0.        , -1.        ],\n",
       "        [-0.19285314, -0.02915521,  0.        , -1.        ],\n",
       "        [-0.16369792, -0.02695067,  0.        , -1.        ],\n",
       "        [-0.13674725, -0.02465811,  0.        , -1.        ],\n",
       "        [-0.11208914, -0.02229813,  0.        , -1.        ],\n",
       "        [-0.08979102, -0.01988828,  0.        , -1.        ],\n",
       "        [-0.06990274, -0.01744305,  0.        , -1.        ],\n",
       "        [-0.05245968, -0.01497395,  0.        , -1.        ],\n",
       "        [-0.03748573, -0.01248974,  0.        , -1.        ],\n",
       "        [-0.02499599, -0.00999677,  0.        , -1.        ],\n",
       "        [-0.01499923, -0.0074993 ,  0.        , -1.        ],\n",
       "        [-0.00749993, -0.00499993,  0.        , -1.        ],\n",
       "        [-0.0025    , -0.0025    ,  0.        , -1.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " -0.3288961267268889,\n",
       " -0.03659458449101587)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_time_steps(x, x_dot, online_model, target_model, replayBuffer, gamma, epsilon, actions, n_samples = 128):\n",
    "    '''Function to sample an number of episode using the online model.\n",
    "    The samples are placed in the replay buffer'''  \n",
    "#    for _ in range(n_episodes):\n",
    "    done = False\n",
    "    i = 0\n",
    "    ## Compute the required number of samples or quite when terminal\n",
    "    while((i < n_samples) and (not done)):\n",
    "        ## Compute the values for the time step\n",
    "        x, x_dot, done, Q_target, Q_online = compute_Q_values(x,x_dot,actions,gamma,epsilon,online_model,target_model) \n",
    "        ## Add new values to the replay buffer\n",
    "        newCase = np.array([x,x_dot,Q_online,Q_target]).reshape((1,4))\n",
    "        replayBuffer = replay_buffer(newCase, replayBuffer)\n",
    "        ## Increment the count of samples\n",
    "        i += 1\n",
    "    return replayBuffer, x, x_dot\n",
    "\n",
    "## Very simple purely operational test case for function\n",
    "## first initialize a numpy buffer array with\n",
    "## elements, x, x_dot, Q_online, Q_target  \n",
    "x_knot = 0.0\n",
    "x_dot_knot = 0.0\n",
    "test_buffer = np.array([x_knot,x_dot_knot,0.0,0.0]).reshape((1,4))\n",
    "actions = [-1.0,0.0,1.0]  \n",
    "sample_time_steps(x_knot, x_dot_knot, function_approx, function_approx, test_buffer, 0.9, 0.05, actions, n_samples = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.4142 - mean_absolute_error: 0.5076\n",
      "Epoch 1/1\n",
      "257/257 [==============================] - 0s 113us/step - loss: 0.6921 - mean_absolute_error: 0.6897\n",
      "Epoch 1/1\n",
      "385/385 [==============================] - 0s 85us/step - loss: 0.7328 - mean_absolute_error: 0.7260\n",
      "Epoch 1/1\n",
      "513/513 [==============================] - 0s 72us/step - loss: 0.6522 - mean_absolute_error: 0.6799\n",
      "Epoch 1/1\n",
      "641/641 [==============================] - 0s 62us/step - loss: 0.5509 - mean_absolute_error: 0.5961\n",
      "Epoch 1/1\n",
      "769/769 [==============================] - 0s 67us/step - loss: 0.4664 - mean_absolute_error: 0.5364\n",
      "Epoch 1/1\n",
      "897/897 [==============================] - 0s 57us/step - loss: 0.3929 - mean_absolute_error: 0.4704\n",
      "Epoch 1/1\n",
      "1025/1025 [==============================] - 0s 80us/step - loss: 0.3310 - mean_absolute_error: 0.4242\n",
      "Epoch 1/1\n",
      "1153/1153 [==============================] - 0s 80us/step - loss: 0.2674 - mean_absolute_error: 0.3680\n",
      "Epoch 1/1\n",
      "1281/1281 [==============================] - 0s 72us/step - loss: 0.2608 - mean_absolute_error: 0.3567\n",
      "Epoch 1/1\n",
      "1409/1409 [==============================] - 0s 92us/step - loss: 0.2422 - mean_absolute_error: 0.3401\n",
      "Epoch 1/1\n",
      "1537/1537 [==============================] - 0s 96us/step - loss: 0.2225 - mean_absolute_error: 0.3305\n",
      "Epoch 1/1\n",
      "1665/1665 [==============================] - 0s 80us/step - loss: 0.2145 - mean_absolute_error: 0.3241\n",
      "Epoch 1/1\n",
      "1793/1793 [==============================] - 0s 77us/step - loss: 0.2012 - mean_absolute_error: 0.3228\n",
      "Epoch 1/1\n",
      "1921/1921 [==============================] - 0s 74us/step - loss: 0.1906 - mean_absolute_error: 0.3221\n",
      "Epoch 1/1\n",
      "2049/2049 [==============================] - 0s 87us/step - loss: 0.1816 - mean_absolute_error: 0.3112\n",
      "Epoch 1/1\n",
      "2177/2177 [==============================] - 0s 49us/step - loss: 0.1604 - mean_absolute_error: 0.2955\n",
      "Epoch 1/1\n",
      "2305/2305 [==============================] - 0s 64us/step - loss: 0.1702 - mean_absolute_error: 0.3071\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 0s 43us/step - loss: 0.1708 - mean_absolute_error: 0.3117\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 0s 46us/step - loss: 0.1721 - mean_absolute_error: 0.3165\n",
      "Epoch 1/1\n",
      "2689/2689 [==============================] - 0s 48us/step - loss: 0.1692 - mean_absolute_error: 0.3137\n",
      "Epoch 1/1\n",
      "2817/2817 [==============================] - 0s 38us/step - loss: 0.1690 - mean_absolute_error: 0.3153\n",
      "Epoch 1/1\n",
      "2945/2945 [==============================] - 0s 40us/step - loss: 0.1613 - mean_absolute_error: 0.3119\n",
      "Epoch 1/1\n",
      "3073/3073 [==============================] - 0s 43us/step - loss: 0.1611 - mean_absolute_error: 0.3125\n",
      "Epoch 1/1\n",
      "3201/3201 [==============================] - 0s 45us/step - loss: 0.1510 - mean_absolute_error: 0.2991\n",
      "Epoch 1/1\n",
      "3329/3329 [==============================] - 0s 40us/step - loss: 0.1465 - mean_absolute_error: 0.2984\n",
      "Epoch 1/1\n",
      "3457/3457 [==============================] - 0s 40us/step - loss: 0.1407 - mean_absolute_error: 0.2921\n",
      "Epoch 1/1\n",
      "3585/3585 [==============================] - 0s 45us/step - loss: 0.1374 - mean_absolute_error: 0.2876\n",
      "Epoch 1/1\n",
      "3713/3713 [==============================] - 0s 44us/step - loss: 0.1346 - mean_absolute_error: 0.2850\n",
      "Epoch 1/1\n",
      "3841/3841 [==============================] - 0s 43us/step - loss: 0.1268 - mean_absolute_error: 0.2764\n",
      "Epoch 1/1\n",
      "3969/3969 [==============================] - 0s 43us/step - loss: 0.1231 - mean_absolute_error: 0.2701\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.1221 - mean_absolute_error: 0.2686\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0968 - mean_absolute_error: 0.2393\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0922 - mean_absolute_error: 0.2339\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0871 - mean_absolute_error: 0.2268\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0786 - mean_absolute_error: 0.2125\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0722 - mean_absolute_error: 0.2017\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0639 - mean_absolute_error: 0.1880\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0550 - mean_absolute_error: 0.1703\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0433 - mean_absolute_error: 0.1512\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0285 - mean_absolute_error: 0.1283\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0295 - mean_absolute_error: 0.1261\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0306 - mean_absolute_error: 0.1239\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0301 - mean_absolute_error: 0.1199\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0295 - mean_absolute_error: 0.1127\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0276 - mean_absolute_error: 0.1060\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0248 - mean_absolute_error: 0.0975\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0225 - mean_absolute_error: 0.0942\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0188 - mean_absolute_error: 0.0895\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0268 - mean_absolute_error: 0.1049\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0323 - mean_absolute_error: 0.1197\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0388 - mean_absolute_error: 0.1326\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0462 - mean_absolute_error: 0.1486\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0501 - mean_absolute_error: 0.1601\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0529 - mean_absolute_error: 0.1668\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0598 - mean_absolute_error: 0.1840\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0593 - mean_absolute_error: 0.1878\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 56us/step - loss: 0.0648 - mean_absolute_error: 0.1988\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 61us/step - loss: 0.0688 - mean_absolute_error: 0.2065\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 54us/step - loss: 0.0739 - mean_absolute_error: 0.2171\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0739 - mean_absolute_error: 0.2193\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0779 - mean_absolute_error: 0.2252\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0787 - mean_absolute_error: 0.2287\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0774 - mean_absolute_error: 0.2266\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0810 - mean_absolute_error: 0.2330\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0789 - mean_absolute_error: 0.2284\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0770 - mean_absolute_error: 0.2249\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0773 - mean_absolute_error: 0.2233\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0741 - mean_absolute_error: 0.2190\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0671 - mean_absolute_error: 0.2053\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0639 - mean_absolute_error: 0.1994\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0549 - mean_absolute_error: 0.1842\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0437 - mean_absolute_error: 0.1661\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0435 - mean_absolute_error: 0.1616\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0433 - mean_absolute_error: 0.1572\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0425 - mean_absolute_error: 0.1510\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0395 - mean_absolute_error: 0.1398\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0358 - mean_absolute_error: 0.1262\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0306 - mean_absolute_error: 0.1130\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0255 - mean_absolute_error: 0.1030\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0173 - mean_absolute_error: 0.0914\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 2.5003 - mean_absolute_error: 0.1170\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 4.9467 - mean_absolute_error: 0.1433\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 7.4284 - mean_absolute_error: 0.1693\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 9.8988 - mean_absolute_error: 0.1936\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 12.3425 - mean_absolute_error: 0.2184\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 14.8118 - mean_absolute_error: 0.2457\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 17.2697 - mean_absolute_error: 0.2757\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 19.6932 - mean_absolute_error: 0.2965\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 22.1865 - mean_absolute_error: 0.3254\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 24.6122 - mean_absolute_error: 0.3622\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 27.0627 - mean_absolute_error: 0.3835\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 29.5235 - mean_absolute_error: 0.4050\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 31.9627 - mean_absolute_error: 0.4443\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 34.4047 - mean_absolute_error: 0.4744\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 36.8637 - mean_absolute_error: 0.5028\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 39.3122 - mean_absolute_error: 0.5406\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 41.7487 - mean_absolute_error: 0.5757\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 44.1591 - mean_absolute_error: 0.6158\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 46.5965 - mean_absolute_error: 0.6554\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 49.0514 - mean_absolute_error: 0.6750\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 51.4396 - mean_absolute_error: 0.7384\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 53.8660 - mean_absolute_error: 0.7961\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 56.3126 - mean_absolute_error: 0.8109\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 63us/step - loss: 58.7502 - mean_absolute_error: 0.8531\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 58us/step - loss: 61.1804 - mean_absolute_error: 0.8682\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 60us/step - loss: 63.5639 - mean_absolute_error: 0.9390\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 65.9749 - mean_absolute_error: 0.9738\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 59us/step - loss: 68.4156 - mean_absolute_error: 1.0022\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 70.7931 - mean_absolute_error: 1.0601\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 52us/step - loss: 73.2294 - mean_absolute_error: 1.0980\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 52us/step - loss: 75.6163 - mean_absolute_error: 1.1213\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 78.0072 - mean_absolute_error: 1.1770\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 80.4585 - mean_absolute_error: 1.2028\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 82.8147 - mean_absolute_error: 1.2671\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 85.2267 - mean_absolute_error: 1.2937\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 87.6236 - mean_absolute_error: 1.3377\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 90.0068 - mean_absolute_error: 1.3874\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 92.4004 - mean_absolute_error: 1.4234\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 94.7960 - mean_absolute_error: 1.4642\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 97.1864 - mean_absolute_error: 1.4941\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 99.5789 - mean_absolute_error: 1.5444\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 101.9718 - mean_absolute_error: 1.5941\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 104.3557 - mean_absolute_error: 1.6252\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 106.7632 - mean_absolute_error: 1.6656\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 109.1260 - mean_absolute_error: 1.7205\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 111.5030 - mean_absolute_error: 1.7683\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 113.9284 - mean_absolute_error: 1.8129\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 116.2516 - mean_absolute_error: 1.8411\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 118.6675 - mean_absolute_error: 1.8922\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 121.0947 - mean_absolute_error: 1.9281\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 123.4051 - mean_absolute_error: 1.9578\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 125.7836 - mean_absolute_error: 2.0069\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 128.1344 - mean_absolute_error: 2.0431\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 130.5297 - mean_absolute_error: 2.1102\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 132.9621 - mean_absolute_error: 2.1417\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 135.3199 - mean_absolute_error: 2.1904\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 137.7296 - mean_absolute_error: 2.2494\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 140.0794 - mean_absolute_error: 2.2683\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 142.4405 - mean_absolute_error: 2.3111\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 58us/step - loss: 144.8174 - mean_absolute_error: 2.3616\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 74us/step - loss: 147.1894 - mean_absolute_error: 2.4126\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 63us/step - loss: 149.5072 - mean_absolute_error: 2.4539\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 50us/step - loss: 151.9394 - mean_absolute_error: 2.4775\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 50us/step - loss: 154.2813 - mean_absolute_error: 2.5593\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 156.6107 - mean_absolute_error: 2.6021\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 159.0178 - mean_absolute_error: 2.6262\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 161.3293 - mean_absolute_error: 2.6828\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 163.7108 - mean_absolute_error: 2.7117\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 166.1389 - mean_absolute_error: 2.7830\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 168.4536 - mean_absolute_error: 2.8058\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 168.3329 - mean_absolute_error: 2.8320\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 168.2337 - mean_absolute_error: 2.8310\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 168.2648 - mean_absolute_error: 2.8812\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 58us/step - loss: 168.1097 - mean_absolute_error: 2.8681\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 168.0170 - mean_absolute_error: 2.8604\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 167.9766 - mean_absolute_error: 2.8911\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 58us/step - loss: 167.8658 - mean_absolute_error: 2.8889\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 167.7818 - mean_absolute_error: 2.8834\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 167.6964 - mean_absolute_error: 2.8973\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 167.6433 - mean_absolute_error: 2.9280\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 167.5106 - mean_absolute_error: 2.9185\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 167.4520 - mean_absolute_error: 2.9284\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 167.2223 - mean_absolute_error: 2.9015\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 167.0646 - mean_absolute_error: 2.8865\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 65us/step - loss: 166.9754 - mean_absolute_error: 2.8964\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 111us/step - loss: 166.9156 - mean_absolute_error: 2.8961\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 63us/step - loss: 166.7107 - mean_absolute_error: 2.8703\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 166.6178 - mean_absolute_error: 2.8929\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 166.5040 - mean_absolute_error: 2.8874\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 166.3492 - mean_absolute_error: 2.8732\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 166.1683 - mean_absolute_error: 2.8444\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 166.0432 - mean_absolute_error: 2.8558\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 165.9452 - mean_absolute_error: 2.8534\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 165.8512 - mean_absolute_error: 2.8669\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 165.6650 - mean_absolute_error: 2.8404\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 165.4412 - mean_absolute_error: 2.8155\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 165.3429 - mean_absolute_error: 2.8242\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 165.0319 - mean_absolute_error: 2.7771\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 164.8534 - mean_absolute_error: 2.7773\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 164.7340 - mean_absolute_error: 2.7844\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 164.5495 - mean_absolute_error: 2.7612\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 3.7659 - mean_absolute_error: 0.9690\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.6381 - mean_absolute_error: 0.6377\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.4499 - mean_absolute_error: 0.5300\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.4138 - mean_absolute_error: 0.5091\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.3870 - mean_absolute_error: 0.4933\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.3417 - mean_absolute_error: 0.4609\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.3428 - mean_absolute_error: 0.4619\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.3060 - mean_absolute_error: 0.4354\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.2979 - mean_absolute_error: 0.4257\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.2645 - mean_absolute_error: 0.3972\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.2403 - mean_absolute_error: 0.3801\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.2330 - mean_absolute_error: 0.3754\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.2131 - mean_absolute_error: 0.3593\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.2006 - mean_absolute_error: 0.3459\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.1879 - mean_absolute_error: 0.3350\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.1673 - mean_absolute_error: 0.3159\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.1652 - mean_absolute_error: 0.3132\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.1543 - mean_absolute_error: 0.3040\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.1466 - mean_absolute_error: 0.2966\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.1405 - mean_absolute_error: 0.2922\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.1312 - mean_absolute_error: 0.2836\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.1275 - mean_absolute_error: 0.2792\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.1229 - mean_absolute_error: 0.2748\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.1151 - mean_absolute_error: 0.2671\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.1122 - mean_absolute_error: 0.2651\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 0.1078 - mean_absolute_error: 0.2619\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.1053 - mean_absolute_error: 0.2575\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 59us/step - loss: 0.1043 - mean_absolute_error: 0.2535\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0981 - mean_absolute_error: 0.2385\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0954 - mean_absolute_error: 0.2291\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0860 - mean_absolute_error: 0.2092\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0734 - mean_absolute_error: 0.1864\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0601 - mean_absolute_error: 0.1609\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0410 - mean_absolute_error: 0.1291\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0157 - mean_absolute_error: 0.0942\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0191 - mean_absolute_error: 0.0978\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0222 - mean_absolute_error: 0.1028\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0247 - mean_absolute_error: 0.1081\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 57us/step - loss: 0.0271 - mean_absolute_error: 0.1166\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0297 - mean_absolute_error: 0.1252\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0302 - mean_absolute_error: 0.1274\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0348 - mean_absolute_error: 0.1387\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0360 - mean_absolute_error: 0.1427\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0433 - mean_absolute_error: 0.1580\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0470 - mean_absolute_error: 0.1656\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0508 - mean_absolute_error: 0.1735\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0549 - mean_absolute_error: 0.1829\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0580 - mean_absolute_error: 0.1914\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0597 - mean_absolute_error: 0.1938\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0609 - mean_absolute_error: 0.1977\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0616 - mean_absolute_error: 0.1985\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0641 - mean_absolute_error: 0.2030\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 77us/step - loss: 0.0641 - mean_absolute_error: 0.2014\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 57us/step - loss: 0.0643 - mean_absolute_error: 0.2008\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 62us/step - loss: 0.0616 - mean_absolute_error: 0.1961\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0577 - mean_absolute_error: 0.1891\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0557 - mean_absolute_error: 0.1865\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0482 - mean_absolute_error: 0.1738\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0433 - mean_absolute_error: 0.1657\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0437 - mean_absolute_error: 0.1635\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0435 - mean_absolute_error: 0.1606\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0422 - mean_absolute_error: 0.1536\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0391 - mean_absolute_error: 0.1441\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0358 - mean_absolute_error: 0.1356\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0325 - mean_absolute_error: 0.1265\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0271 - mean_absolute_error: 0.1155\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0189 - mean_absolute_error: 0.1015\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0215 - mean_absolute_error: 0.1056\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0234 - mean_absolute_error: 0.1075\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 60us/step - loss: 0.0255 - mean_absolute_error: 0.1123\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0263 - mean_absolute_error: 0.1126\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 61us/step - loss: 0.0274 - mean_absolute_error: 0.1157\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0270 - mean_absolute_error: 0.1166\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0271 - mean_absolute_error: 0.1189\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0258 - mean_absolute_error: 0.1184\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0294 - mean_absolute_error: 0.1284\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0321 - mean_absolute_error: 0.1366\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0352 - mean_absolute_error: 0.1441\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0374 - mean_absolute_error: 0.1491\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0383 - mean_absolute_error: 0.1509\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 53us/step - loss: 0.0375 - mean_absolute_error: 0.1503\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 76us/step - loss: 0.0379 - mean_absolute_error: 0.1519\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0371 - mean_absolute_error: 0.1508\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0397 - mean_absolute_error: 0.1553\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 70us/step - loss: 0.0403 - mean_absolute_error: 0.1575\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 0.0410 - mean_absolute_error: 0.1573\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0405 - mean_absolute_error: 0.1572\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0396 - mean_absolute_error: 0.1549\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0386 - mean_absolute_error: 0.1540\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0339 - mean_absolute_error: 0.1444\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0308 - mean_absolute_error: 0.1390\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0325 - mean_absolute_error: 0.1406\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0334 - mean_absolute_error: 0.1411\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0334 - mean_absolute_error: 0.1380\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0322 - mean_absolute_error: 0.1326\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 52us/step - loss: 0.0289 - mean_absolute_error: 0.1242\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0280 - mean_absolute_error: 0.1226\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0239 - mean_absolute_error: 0.1144\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0197 - mean_absolute_error: 0.1064\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0214 - mean_absolute_error: 0.1096\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0232 - mean_absolute_error: 0.1129\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0244 - mean_absolute_error: 0.1132\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0254 - mean_absolute_error: 0.1158\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0249 - mean_absolute_error: 0.1146\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0245 - mean_absolute_error: 0.1141\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 63us/step - loss: 0.0236 - mean_absolute_error: 0.1138\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0213 - mean_absolute_error: 0.1089\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0240 - mean_absolute_error: 0.1162\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0262 - mean_absolute_error: 0.1222\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0271 - mean_absolute_error: 0.1266\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0283 - mean_absolute_error: 0.1283\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0285 - mean_absolute_error: 0.1301\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0290 - mean_absolute_error: 0.1314\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 62us/step - loss: 0.0279 - mean_absolute_error: 0.1301\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0266 - mean_absolute_error: 0.1273\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0290 - mean_absolute_error: 0.1333\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0296 - mean_absolute_error: 0.1335\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0298 - mean_absolute_error: 0.1335\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0302 - mean_absolute_error: 0.1355\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0302 - mean_absolute_error: 0.1352\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0274 - mean_absolute_error: 0.1290\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0261 - mean_absolute_error: 0.1265\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0243 - mean_absolute_error: 0.1229\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0251 - mean_absolute_error: 0.1230\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0250 - mean_absolute_error: 0.1214\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0261 - mean_absolute_error: 0.1229\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0255 - mean_absolute_error: 0.1195\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0242 - mean_absolute_error: 0.1158\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0234 - mean_absolute_error: 0.1153\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0209 - mean_absolute_error: 0.1091\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0177 - mean_absolute_error: 0.1024\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0194 - mean_absolute_error: 0.1064\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0207 - mean_absolute_error: 0.1079\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0212 - mean_absolute_error: 0.1084\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0213 - mean_absolute_error: 0.1074\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0213 - mean_absolute_error: 0.1080\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0206 - mean_absolute_error: 0.1067\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 60us/step - loss: 0.0194 - mean_absolute_error: 0.1043\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 52us/step - loss: 0.0170 - mean_absolute_error: 0.0991\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 56us/step - loss: 0.0192 - mean_absolute_error: 0.1052\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0204 - mean_absolute_error: 0.1085\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0211 - mean_absolute_error: 0.1100\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0219 - mean_absolute_error: 0.1130\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0223 - mean_absolute_error: 0.1135\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0214 - mean_absolute_error: 0.1119\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0210 - mean_absolute_error: 0.1117\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0198 - mean_absolute_error: 0.1097\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0217 - mean_absolute_error: 0.1143\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0220 - mean_absolute_error: 0.1145\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0223 - mean_absolute_error: 0.1146\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0222 - mean_absolute_error: 0.1137\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0221 - mean_absolute_error: 0.1154\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0214 - mean_absolute_error: 0.1129\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0196 - mean_absolute_error: 0.1086\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0180 - mean_absolute_error: 0.1053\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0191 - mean_absolute_error: 0.1072\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0202 - mean_absolute_error: 0.1095\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0205 - mean_absolute_error: 0.1089\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0205 - mean_absolute_error: 0.1074\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0197 - mean_absolute_error: 0.1052\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0189 - mean_absolute_error: 0.1040\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0170 - mean_absolute_error: 0.0997\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0155 - mean_absolute_error: 0.0965\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0165 - mean_absolute_error: 0.0985\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0177 - mean_absolute_error: 0.1000\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0181 - mean_absolute_error: 0.1001\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0184 - mean_absolute_error: 0.1012\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0183 - mean_absolute_error: 0.1015\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0175 - mean_absolute_error: 0.0997\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0165 - mean_absolute_error: 0.0974\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0154 - mean_absolute_error: 0.0956\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0158 - mean_absolute_error: 0.0965\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0173 - mean_absolute_error: 0.1000\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0176 - mean_absolute_error: 0.1009\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0179 - mean_absolute_error: 0.1023\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0183 - mean_absolute_error: 0.1038\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0173 - mean_absolute_error: 0.1013\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0173 - mean_absolute_error: 0.1024\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 57us/step - loss: 0.0158 - mean_absolute_error: 0.0983\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0170 - mean_absolute_error: 0.1012\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0173 - mean_absolute_error: 0.1007\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0183 - mean_absolute_error: 0.1037\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 58us/step - loss: 0.0182 - mean_absolute_error: 0.1033\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0172 - mean_absolute_error: 0.1005\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0170 - mean_absolute_error: 0.1002\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 54us/step - loss: 0.0160 - mean_absolute_error: 0.0976\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0149 - mean_absolute_error: 0.0954\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 50us/step - loss: 0.0152 - mean_absolute_error: 0.0954\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0163 - mean_absolute_error: 0.0983\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 50us/step - loss: 0.0164 - mean_absolute_error: 0.0981\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0163 - mean_absolute_error: 0.0962\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0157 - mean_absolute_error: 0.0947\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0157 - mean_absolute_error: 0.0954\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0147 - mean_absolute_error: 0.0928\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0129 - mean_absolute_error: 0.0877\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0140 - mean_absolute_error: 0.0915\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0145 - mean_absolute_error: 0.0926\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0150 - mean_absolute_error: 0.0923\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0149 - mean_absolute_error: 0.0917\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0150 - mean_absolute_error: 0.0938\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0144 - mean_absolute_error: 0.0918\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0139 - mean_absolute_error: 0.0907\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0128 - mean_absolute_error: 0.0878\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0136 - mean_absolute_error: 0.0896\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0140 - mean_absolute_error: 0.0911\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0148 - mean_absolute_error: 0.0927\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0150 - mean_absolute_error: 0.0936\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0147 - mean_absolute_error: 0.0924\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0140 - mean_absolute_error: 0.0906\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0134 - mean_absolute_error: 0.0894\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0125 - mean_absolute_error: 0.0875\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0134 - mean_absolute_error: 0.0894\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0139 - mean_absolute_error: 0.0909\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0141 - mean_absolute_error: 0.0908\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0141 - mean_absolute_error: 0.0902\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0138 - mean_absolute_error: 0.0895\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0136 - mean_absolute_error: 0.0900\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0127 - mean_absolute_error: 0.0872\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0115 - mean_absolute_error: 0.0835\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0122 - mean_absolute_error: 0.0858\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0128 - mean_absolute_error: 0.0871\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0131 - mean_absolute_error: 0.0873\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0135 - mean_absolute_error: 0.0886\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0132 - mean_absolute_error: 0.0879\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0125 - mean_absolute_error: 0.0853\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0120 - mean_absolute_error: 0.0847\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0110 - mean_absolute_error: 0.0819\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0112 - mean_absolute_error: 0.0818\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0126 - mean_absolute_error: 0.0860\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0124 - mean_absolute_error: 0.0843\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0129 - mean_absolute_error: 0.0860\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0124 - mean_absolute_error: 0.0852\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0120 - mean_absolute_error: 0.0839\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0119 - mean_absolute_error: 0.0840\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0106 - mean_absolute_error: 0.0804\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0116 - mean_absolute_error: 0.0828\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0120 - mean_absolute_error: 0.0839\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0123 - mean_absolute_error: 0.0847\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0126 - mean_absolute_error: 0.0864\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0123 - mean_absolute_error: 0.0858\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0120 - mean_absolute_error: 0.0845\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 32us/step - loss: 0.0114 - mean_absolute_error: 0.0828\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0103 - mean_absolute_error: 0.0794\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0111 - mean_absolute_error: 0.0812\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0115 - mean_absolute_error: 0.0825\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0116 - mean_absolute_error: 0.0826\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0120 - mean_absolute_error: 0.0844\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0118 - mean_absolute_error: 0.0841\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0117 - mean_absolute_error: 0.0836\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0106 - mean_absolute_error: 0.0800\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0097 - mean_absolute_error: 0.0769\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0104 - mean_absolute_error: 0.0789\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0110 - mean_absolute_error: 0.0807\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0111 - mean_absolute_error: 0.0806\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0115 - mean_absolute_error: 0.0816\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0111 - mean_absolute_error: 0.0803\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0107 - mean_absolute_error: 0.0802\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0100 - mean_absolute_error: 0.0773\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0092 - mean_absolute_error: 0.0741\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0099 - mean_absolute_error: 0.0770\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0102 - mean_absolute_error: 0.0782\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0108 - mean_absolute_error: 0.0797\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0104 - mean_absolute_error: 0.0782\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0104 - mean_absolute_error: 0.0776\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0102 - mean_absolute_error: 0.0781\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 50us/step - loss: 0.0094 - mean_absolute_error: 0.0748\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 32us/step - loss: 0.0088 - mean_absolute_error: 0.0739\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 0.0096 - mean_absolute_error: 0.0763\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0099 - mean_absolute_error: 0.0773\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0101 - mean_absolute_error: 0.0772\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0104 - mean_absolute_error: 0.0787\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0104 - mean_absolute_error: 0.0790\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0099 - mean_absolute_error: 0.0774\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0096 - mean_absolute_error: 0.0763\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 53us/step - loss: 0.0086 - mean_absolute_error: 0.0723\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 0.0093 - mean_absolute_error: 0.0754\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 50us/step - loss: 0.0097 - mean_absolute_error: 0.0759\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0099 - mean_absolute_error: 0.0763\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0101 - mean_absolute_error: 0.0767\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0097 - mean_absolute_error: 0.0759\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0094 - mean_absolute_error: 0.0742\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0089 - mean_absolute_error: 0.0731\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0080 - mean_absolute_error: 0.0695\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0087 - mean_absolute_error: 0.0725\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0090 - mean_absolute_error: 0.0730\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 0.0094 - mean_absolute_error: 0.0747\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0094 - mean_absolute_error: 0.0754\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0094 - mean_absolute_error: 0.0745\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0092 - mean_absolute_error: 0.0741\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0087 - mean_absolute_error: 0.0719\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0083 - mean_absolute_error: 0.0708\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0088 - mean_absolute_error: 0.0724\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0090 - mean_absolute_error: 0.0732\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0095 - mean_absolute_error: 0.0753\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0093 - mean_absolute_error: 0.0745\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0095 - mean_absolute_error: 0.0748\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0089 - mean_absolute_error: 0.0728\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0083 - mean_absolute_error: 0.0711\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0076 - mean_absolute_error: 0.0682\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0082 - mean_absolute_error: 0.0709\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0086 - mean_absolute_error: 0.0724\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0089 - mean_absolute_error: 0.0735\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0089 - mean_absolute_error: 0.0730\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0088 - mean_absolute_error: 0.0736\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0088 - mean_absolute_error: 0.0730\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0081 - mean_absolute_error: 0.0702\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0076 - mean_absolute_error: 0.0678\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0082 - mean_absolute_error: 0.0701\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 33us/step - loss: 0.0083 - mean_absolute_error: 0.0699\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0086 - mean_absolute_error: 0.0715\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0085 - mean_absolute_error: 0.0707\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0086 - mean_absolute_error: 0.0717\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0083 - mean_absolute_error: 0.0707\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0077 - mean_absolute_error: 0.0681\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0071 - mean_absolute_error: 0.0663\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0076 - mean_absolute_error: 0.0683\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0081 - mean_absolute_error: 0.0704\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0084 - mean_absolute_error: 0.0718\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0083 - mean_absolute_error: 0.0709\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0081 - mean_absolute_error: 0.0703\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0081 - mean_absolute_error: 0.0703\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0077 - mean_absolute_error: 0.0687\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0070 - mean_absolute_error: 0.0653\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0075 - mean_absolute_error: 0.0672\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0079 - mean_absolute_error: 0.0689\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0082 - mean_absolute_error: 0.0704\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0082 - mean_absolute_error: 0.0704\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0080 - mean_absolute_error: 0.0695\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0076 - mean_absolute_error: 0.0679\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0074 - mean_absolute_error: 0.0667\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0066 - mean_absolute_error: 0.0641\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 36us/step - loss: 0.0071 - mean_absolute_error: 0.0660\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0075 - mean_absolute_error: 0.0677\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0077 - mean_absolute_error: 0.0693\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0080 - mean_absolute_error: 0.0705\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0077 - mean_absolute_error: 0.0684\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 35us/step - loss: 0.0077 - mean_absolute_error: 0.0683\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0073 - mean_absolute_error: 0.0669\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0066 - mean_absolute_error: 0.0635\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 34us/step - loss: 0.0070 - mean_absolute_error: 0.0652\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0072 - mean_absolute_error: 0.0658\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0077 - mean_absolute_error: 0.0683\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0075 - mean_absolute_error: 0.0676\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0074 - mean_absolute_error: 0.0673\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0072 - mean_absolute_error: 0.0660\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0066 - mean_absolute_error: 0.0638\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0062 - mean_absolute_error: 0.0625\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0066 - mean_absolute_error: 0.0643\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0068 - mean_absolute_error: 0.0654\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0070 - mean_absolute_error: 0.0662\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0071 - mean_absolute_error: 0.0661\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0069 - mean_absolute_error: 0.0657\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0067 - mean_absolute_error: 0.0640\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0065 - mean_absolute_error: 0.0638\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0059 - mean_absolute_error: 0.0605\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0063 - mean_absolute_error: 0.0619\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0065 - mean_absolute_error: 0.0632\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0067 - mean_absolute_error: 0.0637\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0069 - mean_absolute_error: 0.0649\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0066 - mean_absolute_error: 0.0633\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0065 - mean_absolute_error: 0.0625\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0060 - mean_absolute_error: 0.0604\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0056 - mean_absolute_error: 0.0584\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0059 - mean_absolute_error: 0.0600\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0063 - mean_absolute_error: 0.0627\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0064 - mean_absolute_error: 0.0631\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0065 - mean_absolute_error: 0.0632\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0063 - mean_absolute_error: 0.0625\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0061 - mean_absolute_error: 0.0613\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0059 - mean_absolute_error: 0.0606\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0054 - mean_absolute_error: 0.0586\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0059 - mean_absolute_error: 0.0611\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0061 - mean_absolute_error: 0.0627\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0063 - mean_absolute_error: 0.0634\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0063 - mean_absolute_error: 0.0634\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0061 - mean_absolute_error: 0.0618\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0060 - mean_absolute_error: 0.0608\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0058 - mean_absolute_error: 0.0597\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0053 - mean_absolute_error: 0.0574\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0056 - mean_absolute_error: 0.0591\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0059 - mean_absolute_error: 0.0609\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0061 - mean_absolute_error: 0.0617\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0062 - mean_absolute_error: 0.0614\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0060 - mean_absolute_error: 0.0601\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0058 - mean_absolute_error: 0.0591\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0056 - mean_absolute_error: 0.0581\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0052 - mean_absolute_error: 0.0568\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0054 - mean_absolute_error: 0.0587\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0057 - mean_absolute_error: 0.0603\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0058 - mean_absolute_error: 0.0608\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0059 - mean_absolute_error: 0.0610\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0056 - mean_absolute_error: 0.0589\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0056 - mean_absolute_error: 0.0590\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0056 - mean_absolute_error: 0.0598\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0053 - mean_absolute_error: 0.0649\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0057 - mean_absolute_error: 0.0671\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0062 - mean_absolute_error: 0.0682\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0066 - mean_absolute_error: 0.0680\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0067 - mean_absolute_error: 0.0671\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0068 - mean_absolute_error: 0.0671\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0067 - mean_absolute_error: 0.0678\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0064 - mean_absolute_error: 0.0679\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0060 - mean_absolute_error: 0.0668\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0065 - mean_absolute_error: 0.0684\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0068 - mean_absolute_error: 0.0690\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0071 - mean_absolute_error: 0.0692\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0071 - mean_absolute_error: 0.0716\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0071 - mean_absolute_error: 0.0726\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0068 - mean_absolute_error: 0.0736\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0065 - mean_absolute_error: 0.0730\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0060 - mean_absolute_error: 0.0715\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0065 - mean_absolute_error: 0.0731\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0068 - mean_absolute_error: 0.0737\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0071 - mean_absolute_error: 0.0733\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0071 - mean_absolute_error: 0.0719\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 38us/step - loss: 0.0071 - mean_absolute_error: 0.0699\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0069 - mean_absolute_error: 0.0698\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0065 - mean_absolute_error: 0.0693\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0061 - mean_absolute_error: 0.0680\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0064 - mean_absolute_error: 0.0689\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0065 - mean_absolute_error: 0.0688\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0065 - mean_absolute_error: 0.0675\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0064 - mean_absolute_error: 0.0654\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0062 - mean_absolute_error: 0.0650\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0058 - mean_absolute_error: 0.0647\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0052 - mean_absolute_error: 0.0635\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0046 - mean_absolute_error: 0.0614\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0049 - mean_absolute_error: 0.0628\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0052 - mean_absolute_error: 0.0633\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0054 - mean_absolute_error: 0.0628\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0054 - mean_absolute_error: 0.0612\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0053 - mean_absolute_error: 0.0602\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0051 - mean_absolute_error: 0.0601\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0048 - mean_absolute_error: 0.0597\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0044 - mean_absolute_error: 0.0582\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 37us/step - loss: 0.0048 - mean_absolute_error: 0.0595\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0050 - mean_absolute_error: 0.0600\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0052 - mean_absolute_error: 0.0595\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0052 - mean_absolute_error: 0.0590\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 40us/step - loss: 0.0051 - mean_absolute_error: 0.0599\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 57us/step - loss: 0.0049 - mean_absolute_error: 0.0606\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0046 - mean_absolute_error: 0.0600\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0042 - mean_absolute_error: 0.0586\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 53us/step - loss: 0.0045 - mean_absolute_error: 0.0599\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0048 - mean_absolute_error: 0.0603\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 56us/step - loss: 0.0050 - mean_absolute_error: 0.0601\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0050 - mean_absolute_error: 0.0591\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0050 - mean_absolute_error: 0.0592\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0048 - mean_absolute_error: 0.0597\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0046 - mean_absolute_error: 0.0593\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 60us/step - loss: 0.0042 - mean_absolute_error: 0.0580\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 80us/step - loss: 0.0045 - mean_absolute_error: 0.0590\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 81us/step - loss: 0.0046 - mean_absolute_error: 0.0590\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0046 - mean_absolute_error: 0.0583\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0046 - mean_absolute_error: 0.0565\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 74us/step - loss: 0.0045 - mean_absolute_error: 0.0555\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0042 - mean_absolute_error: 0.0552\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0039 - mean_absolute_error: 0.0545\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 56us/step - loss: 0.0035 - mean_absolute_error: 0.0528\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 70us/step - loss: 0.0037 - mean_absolute_error: 0.0538\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 79us/step - loss: 0.0038 - mean_absolute_error: 0.0539\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 66us/step - loss: 0.0039 - mean_absolute_error: 0.0531\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 64us/step - loss: 0.0039 - mean_absolute_error: 0.0516\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0038 - mean_absolute_error: 0.0503\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0036 - mean_absolute_error: 0.0502\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0033 - mean_absolute_error: 0.0495\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 74us/step - loss: 0.0030 - mean_absolute_error: 0.0481\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 67us/step - loss: 0.0032 - mean_absolute_error: 0.0492\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0034 - mean_absolute_error: 0.0494\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 59us/step - loss: 0.0035 - mean_absolute_error: 0.0491\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0035 - mean_absolute_error: 0.0482\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0034 - mean_absolute_error: 0.0486\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0033 - mean_absolute_error: 0.0488\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0031 - mean_absolute_error: 0.0484\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0028 - mean_absolute_error: 0.0472\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0031 - mean_absolute_error: 0.0484\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0032 - mean_absolute_error: 0.0488\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0034 - mean_absolute_error: 0.0486\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0034 - mean_absolute_error: 0.0483\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0034 - mean_absolute_error: 0.0490\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0033 - mean_absolute_error: 0.0496\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0031 - mean_absolute_error: 0.0492\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0029 - mean_absolute_error: 0.0482\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0031 - mean_absolute_error: 0.0490\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0032 - mean_absolute_error: 0.0492\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 61us/step - loss: 0.0032 - mean_absolute_error: 0.0487\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0032 - mean_absolute_error: 0.0472\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 0.0031 - mean_absolute_error: 0.0466\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 55us/step - loss: 0.0029 - mean_absolute_error: 0.0467\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0027 - mean_absolute_error: 0.0461\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0025 - mean_absolute_error: 0.0448\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0027 - mean_absolute_error: 0.0457\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 0.0028 - mean_absolute_error: 0.0459\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 54us/step - loss: 0.0029 - mean_absolute_error: 0.0455\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 62us/step - loss: 0.0029 - mean_absolute_error: 0.0443\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0028 - mean_absolute_error: 0.0431\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 53us/step - loss: 0.0027 - mean_absolute_error: 0.0429\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 62us/step - loss: 0.0025 - mean_absolute_error: 0.0425\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 84us/step - loss: 0.0023 - mean_absolute_error: 0.0413\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 70us/step - loss: 0.0025 - mean_absolute_error: 0.0424\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 72us/step - loss: 0.0026 - mean_absolute_error: 0.0428\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.042 - 0s 86us/step - loss: 0.0027 - mean_absolute_error: 0.0426\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 70us/step - loss: 0.0027 - mean_absolute_error: 0.0432\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.044 - 0s 85us/step - loss: 0.0027 - mean_absolute_error: 0.0443\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 85us/step - loss: 0.0026 - mean_absolute_error: 0.0445\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 72us/step - loss: 0.0025 - mean_absolute_error: 0.0444\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 85us/step - loss: 0.0023 - mean_absolute_error: 0.0434\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 75us/step - loss: 0.0025 - mean_absolute_error: 0.0444\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 70us/step - loss: 0.0026 - mean_absolute_error: 0.0448\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 74us/step - loss: 0.0027 - mean_absolute_error: 0.0444\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.043 - 0s 85us/step - loss: 0.0027 - mean_absolute_error: 0.0438\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.044 - 0s 84us/step - loss: 0.0027 - mean_absolute_error: 0.0440\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 69us/step - loss: 0.0027 - mean_absolute_error: 0.0443\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 93us/step - loss: 0.0025 - mean_absolute_error: 0.0440\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 73us/step - loss: 0.0023 - mean_absolute_error: 0.0432\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 72us/step - loss: 0.0025 - mean_absolute_error: 0.0439\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 74us/step - loss: 0.0025 - mean_absolute_error: 0.0437\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.043 - 0s 85us/step - loss: 0.0025 - mean_absolute_error: 0.0431\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 111us/step - loss: 0.0025 - mean_absolute_error: 0.0419\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 87us/step - loss: 0.0024 - mean_absolute_error: 0.0406\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0023 - mean_absolute_error: 0.0403\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0021 - mean_absolute_error: 0.0396\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0018 - mean_absolute_error: 0.0383\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0019 - mean_absolute_error: 0.0389\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0020 - mean_absolute_error: 0.0389\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 59us/step - loss: 0.0020 - mean_absolute_error: 0.0384\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 70us/step - loss: 0.0020 - mean_absolute_error: 0.0372\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 85us/step - loss: 0.0020 - mean_absolute_error: 0.0361\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 68us/step - loss: 0.0019 - mean_absolute_error: 0.0358\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0017 - mean_absolute_error: 0.0353\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 74us/step - loss: 0.0015 - mean_absolute_error: 0.0342\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 58us/step - loss: 0.0017 - mean_absolute_error: 0.0351\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 39us/step - loss: 0.0018 - mean_absolute_error: 0.0354\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0018 - mean_absolute_error: 0.0351\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0018 - mean_absolute_error: 0.0349\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 60us/step - loss: 0.0018 - mean_absolute_error: 0.0355\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 81us/step - loss: 0.0018 - mean_absolute_error: 0.0358\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 66us/step - loss: 0.0017 - mean_absolute_error: 0.0355\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0015 - mean_absolute_error: 0.0346\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0016 - mean_absolute_error: 0.0354\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0017 - mean_absolute_error: 0.0356\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0017 - mean_absolute_error: 0.0351\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0017 - mean_absolute_error: 0.0349\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 56us/step - loss: 0.0017 - mean_absolute_error: 0.0351\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0016 - mean_absolute_error: 0.0354\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0015 - mean_absolute_error: 0.0350\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0014 - mean_absolute_error: 0.0341\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0015 - mean_absolute_error: 0.0346\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0015 - mean_absolute_error: 0.0347\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0015 - mean_absolute_error: 0.0342\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0015 - mean_absolute_error: 0.0333\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0015 - mean_absolute_error: 0.0320\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0014 - mean_absolute_error: 0.0311\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 56us/step - loss: 0.0013 - mean_absolute_error: 0.0305\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0012 - mean_absolute_error: 0.0295\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0013 - mean_absolute_error: 0.0302\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0013 - mean_absolute_error: 0.0303\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0014 - mean_absolute_error: 0.0300\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0014 - mean_absolute_error: 0.0298\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0013 - mean_absolute_error: 0.0300\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0013 - mean_absolute_error: 0.0302\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0012 - mean_absolute_error: 0.0299\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0011 - mean_absolute_error: 0.0290\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0012 - mean_absolute_error: 0.0298\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0013 - mean_absolute_error: 0.0303\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 49us/step - loss: 0.0013 - mean_absolute_error: 0.0303\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0014 - mean_absolute_error: 0.0308\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0014 - mean_absolute_error: 0.0316\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0013 - mean_absolute_error: 0.0319\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0013 - mean_absolute_error: 0.0319\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0012 - mean_absolute_error: 0.0314\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0013 - mean_absolute_error: 0.0320\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0013 - mean_absolute_error: 0.0320\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0014 - mean_absolute_error: 0.0317\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0014 - mean_absolute_error: 0.0311\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0014 - mean_absolute_error: 0.0309\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0013 - mean_absolute_error: 0.0309\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0012 - mean_absolute_error: 0.0307\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0011 - mean_absolute_error: 0.0299\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 51us/step - loss: 0.0012 - mean_absolute_error: 0.0302\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 0.0012 - mean_absolute_error: 0.0302\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 110us/step - loss: 0.0012 - mean_absolute_error: 0.0296\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 75us/step - loss: 0.0012 - mean_absolute_error: 0.0287\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.027 - 0s 73us/step - loss: 0.0011 - mean_absolute_error: 0.0276\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 74us/step - loss: 0.0010 - mean_absolute_error: 0.0271\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 75us/step - loss: 9.5649e-04 - mean_absolute_error: 0.0265\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 97us/step - loss: 8.3771e-04 - mean_absolute_error: 0.0256\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 83us/step - loss: 9.1778e-04 - mean_absolute_error: 0.0263\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 73us/step - loss: 9.8194e-04 - mean_absolute_error: 0.0266\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 98us/step - loss: 0.0010 - mean_absolute_error: 0.0263\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 111us/step - loss: 0.0010 - mean_absolute_error: 0.0259\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 68us/step - loss: 0.0010 - mean_absolute_error: 0.0258\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 60us/step - loss: 9.8183e-04 - mean_absolute_error: 0.0260\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 9.2570e-04 - mean_absolute_error: 0.0258\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 8.4402e-04 - mean_absolute_error: 0.0252\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 45us/step - loss: 9.2613e-04 - mean_absolute_error: 0.0259\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 9.9195e-04 - mean_absolute_error: 0.0263\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 48us/step - loss: 0.0010 - mean_absolute_error: 0.0265\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0011 - mean_absolute_error: 0.0275\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0010 - mean_absolute_error: 0.0282\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 0.0010 - mean_absolute_error: 0.0284\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 9.8331e-04 - mean_absolute_error: 0.0283\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 9.1734e-04 - mean_absolute_error: 0.0278\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 9.7437e-04 - mean_absolute_error: 0.0283\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 0.0010 - mean_absolute_error: 0.0285\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0010 - mean_absolute_error: 0.0282\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 0.0010 - mean_absolute_error: 0.0275\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 47us/step - loss: 0.0010 - mean_absolute_error: 0.0268\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 9.7249e-04 - mean_absolute_error: 0.0266\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 9.1528e-04 - mean_absolute_error: 0.0263\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 8.3787e-04 - mean_absolute_error: 0.0256\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 46us/step - loss: 8.6987e-04 - mean_absolute_error: 0.0259\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 43us/step - loss: 8.8490e-04 - mean_absolute_error: 0.0258\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 42us/step - loss: 8.7746e-04 - mean_absolute_error: 0.0252\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 53us/step - loss: 8.5408e-04 - mean_absolute_error: 0.0243\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 41us/step - loss: 8.1364e-04 - mean_absolute_error: 0.0233\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 53us/step - loss: 7.5196e-04 - mean_absolute_error: 0.0226\n",
      "Epoch 1/1\n",
      "4097/4097 [==============================] - 0s 44us/step - loss: 6.7354e-04 - mean_absolute_error: 0.0220\n"
     ]
    }
   ],
   "source": [
    "def DQN(n_cycles = 800, samples_step = 128, gamma = 0.9, epsilon = 0.01, alpha = 0.1, \n",
    "               target_update_cycles = 8, batch_size = 32, a_knot = 0.0, x_dot_knot = 0.0,\n",
    "               a_knot_prime = 0.0, x_dot_knot_prime = 0.0, train_epochs = 1):\n",
    "    ## Possible actions\n",
    "    actions = [-1.0,0.0,1.0]\n",
    "    \n",
    "    ## Initialize state\n",
    "    x = x_knot\n",
    "    x_dot = x_dot_knot\n",
    "    x_prime = a_knot_prime\n",
    "    x_dot_knot = x_dot_knot_prime\n",
    "    \n",
    "    ## Define the Keras model\n",
    "    target_model = DL_model()\n",
    "    online_model = DL_model()\n",
    "    \n",
    "    ## Initialize replay buffer\n",
    "    replayBuffer = np.array([x_knot,x_dot_knot,0.0,0.0]).reshape((1,4))\n",
    "\n",
    "    ## Loop over the training cycles\n",
    "    T = 0  # Cycle counter\n",
    "    for _ in range(n_cycles):\n",
    "        \n",
    "        ## Sample  \n",
    "        replayBuffer, x, x_dot = sample_time_steps(x, x_dot, online_model, target_model, replayBuffer, gamma, epsilon, actions, n_samples = samples_step)\n",
    "        \n",
    "        ## Train the online model using the samples\n",
    "        online_model.fit(replayBuffer[:,:3], replayBuffer[:,3], epochs = train_epochs, batch_size = batch_size)\n",
    "    \n",
    "        ## Update target model if enough cycles\n",
    "        if((T % target_update_cycles) == 0): target_model.set_weights(online_model.get_weights())  \n",
    "        \n",
    "        ## print some progress and update counter\n",
    "#        print('Cycles = ' + str(T))\n",
    "        T += 1\n",
    "    \n",
    "    return(function_approx)  \n",
    "\n",
    "DQNModel = DQN()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of time steps required to reach the goal for each episode seems reasonable. However, as you have, no doubt noticed, this time required for even these 10 episodes is rather lengthy. In reality, thousands or tens of thousands of episodes are likely required to find a good approximation for the action values. This approximation would then be used to find a greedy policy given state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07 0.07 0.0 False\n",
      "0.13755492271318964 0.06755492271318964 0.0 False\n",
      "0.2028197070103649 0.06526478429717526 0.0 False\n",
      "0.2660331668978672 0.06321345988750231 0.0 False\n",
      "0.32750145482271104 0.061468287924843844 0.0 False\n",
      "0.387582390412412 0.06008093558970094 0.0 False\n",
      "0.44667127747574575 0.05908888706333375 0.0 False\n",
      "0.5 0.05851703870800253 0.0 True\n",
      "0.5 0.058340195703833274 0.0 True\n",
      "0.5 0.058163352699664016 0.0 True\n"
     ]
    }
   ],
   "source": [
    "def policy_time_step(x, x_dot, target_model, actions):\n",
    "    '''Function uses a greedy policy to take a time step with the greatest action value\n",
    "    as predicted by the target model. The function also returns if the episode is done''' \n",
    "    ## Find the action with the largest prediced value for the positon and velocity\n",
    "    Q_target = []\n",
    "    ## Iterate over all actions to find Q values\n",
    "    for a in actions:\n",
    "        Q_target.append(target_model.predict(np.array([[x,x_dot,a]]))[0][0])\n",
    "    ## Find the action with max Q\n",
    "    max_index = np.argmax(Q_target)\n",
    "    ## Finally compute the state following the action with the highest value\n",
    "    x_prime, x_dot_prime, done, reward = sim_car(x, x_dot, actions[max_index])\n",
    "    return x_prime, x_dot_prime, actions[max_index], done\n",
    "\n",
    "\n",
    "## Simple test case for the function\n",
    "x = 0.0\n",
    "x_dot = 1.0\n",
    "for _ in (range(10)):\n",
    "    x, x_dot, action, done = policy_time_step(x,x_dot,DQNModel,actions)\n",
    "    print(x, x_dot, action, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting positon = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_car_a(x, x_dot, a):    \n",
    "    ## Plot car position\n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    ax1 = fig.add_subplot(311)    \n",
    "    ax1.plot(x)\n",
    "    ax1.set_ylabel('Positon of car')\n",
    "    \n",
    "    ## PLot car velocity\n",
    "    ax2 = fig.add_subplot(312)  \n",
    "    ax2.plot(x_dot)\n",
    "    ax2.set_ylabel('Velocity of car')\n",
    "    \n",
    "    ## PLot acceleration\n",
    "    ax2 = fig.add_subplot(313)  \n",
    "    ax2.plot(a)\n",
    "    ax2.set_ylabel('Acceleration of car')\n",
    "    ax2.set_xlabel('Time')\n",
    "    \n",
    "## Initialize the car state\n",
    "a = [0.0]\n",
    "x_dot = [0.0]\n",
    "x = [0.0]\n",
    "print('Starting positon = ' + str(x[0]))\n",
    "\n",
    "## Iterate until termination\n",
    "i = 0    \n",
    "done = False\n",
    "#while not done:\n",
    "for i in range(1000):    \n",
    "    ## Update the position and velocity    \n",
    "    x_temp, x_dot_temp, action, done = policy_time_step(x[i],x_dot[i],DQNModel,actions)\n",
    "    x.append(x_temp)\n",
    "    x_dot.append(x_dot_temp)\n",
    "    a.append(action)\n",
    "    \n",
    "        \n",
    "plot_car_a(x,x_dot,a)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Off-Policy Function Approximation Algorithms\n",
    "\n",
    "In the foregoing example, we have used a rather naive approach to off-policy reinforcement learning with function approximation. Much better algorithms exist, including **eligibility trace** methods and **policy gradient** algorithms. Unfortunately, these algorithms are beyond the scope of this course. Additional information on these algorithms can be found in chapters 12 and 13 of Sutton and Barto, second edition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2018, 2019, Stephen F. Elston. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
